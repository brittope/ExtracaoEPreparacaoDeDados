{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01b4d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(extrai_referencias(xlm)) == 53, len(extrai_referencias(xml))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fcb4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from pathlib import Path\n",
    "from typing import Union, List, Dict, Optional\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4831821d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de referências: 53\n",
      "DUnE: Dataset for Unified Editing — Afra Akyürek, Eric Pan, Garry Kuwanto, Derry Wijaya 2023\n",
      "Bluex: A benchmark based on brazilian leading universities entrance exams — Thales Sales Almeida, Thiago Laitz, Giovana Bonás, Rodrigo Nogueira 2023\n",
      "Revealing the structure of language model capabilities — Ryan Burnell, Han Hao, R Andrew, Jose Conway, Orallo Hernandez 2023\n",
      "Total de referências: 53\n",
      "DUnE: Dataset for Unified Editing\n",
      "Bluex: A benchmark based on brazilian leading universities entrance exams\n",
      "Revealing the structure of language model capabilities\n",
      "Rethink reporting of evaluation results in AI\n",
      "Stochastic Chameleons: Irrelevant Context Hallucinations Reveal Class-Based (Mis)Generalization in LLMs\n",
      "MATHWELL: Generating Educational Math Word Problems Using Teacher Annotations\n",
      "Training verifiers to solve math word problems\n",
      "Coefficient alpha and the internal structure of tests\n",
      "Word problems: a review of linguistic and numerical factors contributing to their difficulty\n",
      "Understanding and using factor scores: Considerations for the applied researcher\n",
      "Faith and fate: Limits of transformers on compositionality\n",
      "Hardmath: A benchmark dataset for challenging problems in applied mathematics\n",
      "Program factor at 10: Origins, development and future directions\n",
      "Exploratory Factor Analysis\n",
      "Reasoning in Large Language Models Through Symbolic Math Word Problems\n",
      "Unidimensionality and interpretability of psychological instruments.\n",
      "Solving math word problems by combining language models with symbolic solvers\n",
      "The Many Faces of Robustness: A Critical Analysis of Out-of-Distribution Generalization\n",
      "Not all llm reasoners are created equal\n",
      "Cadernos de Estudos e Pesquisas em Políticas Educacionais\n",
      "Cognitive processes, linguistic factors, and arithmetic word problem success: a review of behavioral studies\n",
      "Solving for X and Beyond: Can Large Language Models Solve Complex Math Problems with More-Than-Two Unknowns?\n",
      "MAWPS: A Math Word Problem Repository\n",
      "Intuitive vs analytical thinking: four perspectives\n",
      "Zebralogic: On the scaling limits of llms for logical reasoning\n",
      "Multimodal ArXiv: A Dataset for Improving Scientific Comprehension of Large Vision-Language Models\n",
      "Examining the behavior of llm architectures within the framework of standardized national exams in brazil\n",
      "Factor: A computer program to fit the exploratory factor analysis model\n",
      "SymPy: symbolic computing in Python\n",
      "Gsm-symbolic: Understanding the limitations of mathematical reasoning in large language models\n",
      "tinybenchmarks: evaluating llms with fewer examples\n",
      "What makes mathematical word problem solving challenging? exploring the roles of word problem characteristics, text comprehension, and arithmetic skills\n",
      "Reasoning about quantities in natural language\n",
      "Positional description matters for transformers arithmetic\n",
      "Factor analysis as a tool for survey analysis\n",
      "Advances in automatically solving the enem\n",
      "What makes math word problems challenging for LLMs?\n",
      "Different complex word problems require different combinations of cognitive skills\n",
      "When reading meets mathematics: Using eye movements to analyze complex word problem solving\n",
      "The use of cronbach's alpha when developing and reporting research instruments in science education\n",
      "A comparison of selected empirical methods for assessing the structure of responses to test items\n",
      "Making sense of Cronbach's alpha\n",
      "Dimensionality assessment of ordered polytomous items with parallel analysis\n",
      "How to build a benchmark\n",
      "Word problems in mathematics education: A survey\n",
      "Task characteristics associated with mathematical word problem-solving performance among elementary school-aged children: a systematic review and metaanalysis\n",
      "Evaluating mathematical reasoning beyond accuracy\n",
      "Adversarial math word problem generation\n",
      "Errorradar: Benchmarking complex mathematical reasoning of multimodal large language models via error detection\n",
      "Rationales for answers to simple math word problems confuse large language models\n",
      "Multiple-choice questions are efficient and robust llm evaluators\n",
      "Processbench: Identifying process errors in mathematical reasoning\n",
      "Solving math word problems via cooperative reasoning induced language models\n"
     ]
    }
   ],
   "source": [
    "def _text(node: Optional[etree._Element]) -> Optional[str]:\n",
    "    if node is None:\n",
    "        return None\n",
    "    txt = \" \".join(node.itertext()).strip()\n",
    "    return txt or None\n",
    "\n",
    "def _first(match_list):\n",
    "    return match_list[0] if match_list else None\n",
    "\n",
    "def _authors(bibl_struct: etree._Element) -> List[str]:\n",
    "    autores = []\n",
    "    for path in [\n",
    "        \".//*[local-name()='analytic']/*[local-name()='author']\",\n",
    "        \".//*[local-name()='monogr']/*[local-name()='author']\",\n",
    "        \".//*[local-name()='author']\",\n",
    "    ]:\n",
    "        for auth in bibl_struct.xpath(path):\n",
    "            pers_nodes = auth.xpath(\".//*[local-name()='persName']\")\n",
    "            if pers_nodes:\n",
    "                pers = pers_nodes[0]\n",
    "                forename = _text(_first(pers.xpath(\".//*[local-name()='forename']\"))) or \"\"\n",
    "                surname  = _text(_first(pers.xpath(\".//*[local-name()='surname']\"))) or \"\"\n",
    "                nome = (forename + \" \" + surname).strip()\n",
    "                if nome:\n",
    "                    autores.append(nome)\n",
    "                    continue\n",
    "            nome = _text(auth)\n",
    "            if nome:\n",
    "                autores.append(nome)\n",
    "    # remove duplicatas mantendo ordem\n",
    "    seen, uniq = set(), []\n",
    "    for a in autores:\n",
    "        if a not in seen:\n",
    "            seen.add(a)\n",
    "            uniq.append(a)\n",
    "    return uniq\n",
    "\n",
    "def _year(bibl_struct: etree._Element) -> Optional[str]:\n",
    "    date = _first(bibl_struct.xpath(\".//*[local-name()='date']\"))\n",
    "    if date is not None:\n",
    "        when = date.get(\"when\")\n",
    "        if when:\n",
    "            return when[:4]\n",
    "        txt = _text(date)\n",
    "        if txt:\n",
    "            m = re.search(r\"\\b(1[6-9]\\d{2}|20\\d{2}|21\\d{2})\\b\", txt)\n",
    "            if m:\n",
    "                return m.group(0)\n",
    "    return None\n",
    "\n",
    "def _title(bibl_struct: etree._Element) -> Optional[str]:\n",
    "    for path in [\n",
    "        \".//*[local-name()='analytic']/*[local-name()='title']\",\n",
    "        \".//*[local-name()='monogr']/*[local-name()='title']\",\n",
    "        \".//*[local-name()='title']\",\n",
    "    ]:\n",
    "        t = _first(bibl_struct.xpath(path))\n",
    "        if t is not None:\n",
    "            txt = _text(t)\n",
    "            if txt:\n",
    "                return txt\n",
    "    return None\n",
    "\n",
    "def _container_title(bibl_struct: etree._Element) -> Optional[str]:\n",
    "    t = _first(bibl_struct.xpath(\".//*[local-name()='monogr']/*[local-name()='title']\"))\n",
    "    return _text(t) if t is not None else None\n",
    "\n",
    "def _idno(bibl_struct: etree._Element, idtype: str) -> Optional[str]:\n",
    "    node = _first(bibl_struct.xpath(f\".//*[local-name()='idno' and @type='{idtype}']\"))\n",
    "    return _text(node) if node is not None else None\n",
    "\n",
    "def _pages(bibl_struct: etree._Element) -> Optional[str]:\n",
    "    scope = _first(bibl_struct.xpath(\".//*[local-name()='biblScope' and @type='pp']\"))\n",
    "    if scope is not None:\n",
    "        from_p = scope.get(\"from\")\n",
    "        to_p = scope.get(\"to\")\n",
    "        if from_p and to_p:\n",
    "            return f\"{from_p}-{to_p}\"\n",
    "        txt = _text(scope)\n",
    "        if txt:\n",
    "            return txt\n",
    "    return None\n",
    "\n",
    "def extrai_referencias(xml_input: Union[str, bytes, Path, etree._ElementTree]) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Extrai todas as referências de um arquivo TEI, ignorando o biblStruct do próprio paper.\n",
    "    \"\"\"\n",
    "    if isinstance(xml_input, etree._ElementTree):\n",
    "        tree = xml_input\n",
    "    else:\n",
    "        if isinstance(xml_input, (str, Path)) and Path(str(xml_input)).exists():\n",
    "            tree = etree.parse(str(xml_input))\n",
    "        else:\n",
    "            parser = etree.XMLParser(remove_comments=True, recover=True)\n",
    "            root = etree.fromstring(\n",
    "                xml_input.encode(\"utf-8\") if isinstance(xml_input, str) else xml_input,\n",
    "                parser=parser\n",
    "            )\n",
    "            tree = etree.ElementTree(root)\n",
    "\n",
    "    # Captura apenas referências dentro de <listBibl> ou <back>\n",
    "    bibl_structs = tree.xpath(\n",
    "        \".//*[local-name()='listBibl']//*[local-name()='biblStruct'] | \"\n",
    "        \".//*[local-name()='listBibl']//*[local-name()='bibl'] | \"\n",
    "        \".//*[local-name()='back']//*[local-name()='biblStruct'] | \"\n",
    "        \".//*[local-name()='back']//*[local-name()='bibl']\"\n",
    "    )\n",
    "\n",
    "    refs: List[Dict] = []\n",
    "    for b in bibl_structs:\n",
    "        ref = {\n",
    "            \"xml_id\": b.get(\"{http://www.w3.org/XML/1998/namespace}id\"),\n",
    "            \"type\": b.get(\"type\"),\n",
    "            \"title\": _title(b),\n",
    "            \"container_title\": _container_title(b),\n",
    "            \"authors\": _authors(b),\n",
    "            \"year\": _year(b),\n",
    "            \"pages\": _pages(b),\n",
    "            \"publisher\": _text(_first(b.xpath(\".//*[local-name()='publisher']\"))),\n",
    "            \"pub_place\": _text(_first(b.xpath(\".//*[local-name()='pubPlace']\"))),\n",
    "            \"doi\": _idno(b, \"DOI\"),\n",
    "            \"isbn\": _idno(b, \"ISBN\"),\n",
    "            \"issn\": _idno(b, \"ISSN\"),\n",
    "            \"url\": _text(_first(b.xpath(\".//*[local-name()='ref' and @target]\"))) or\n",
    "                   _first([n.get(\"target\") for n in b.xpath(\".//*[local-name()='ref' and @target]\")]) or\n",
    "                   _idno(b, \"URL\"),\n",
    "            \"xml\": etree.tostring(b, encoding=\"unicode\")\n",
    "        }\n",
    "        refs.append(ref)\n",
    "\n",
    "    return refs\n",
    "\n",
    "# ---------------------------\n",
    "# Exemplo de uso:\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    caminho = \"../DataFrames/2025.findings-acl.656.pdf.tei.xml\"  # coloque seu arquivo TEI aqui\n",
    "    referencias = extrai_referencias(caminho)\n",
    "    print(f\"Total de referências: {len(referencias)}\")\n",
    "    for r in referencias[:3]:\n",
    "        print(r[\"title\"], \"—\", \", \".join(r[\"authors\"]), r.get(\"year\"))\n",
    "\n",
    "    # Lista apenas com os títulos das referências\n",
    "    titulos = [r[\"title\"] for r in referencias if r[\"title\"]]\n",
    "    \n",
    "    print(f\"Total de referências: {len(titulos)}\")\n",
    "    for t in titulos:\n",
    "        print(t)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
