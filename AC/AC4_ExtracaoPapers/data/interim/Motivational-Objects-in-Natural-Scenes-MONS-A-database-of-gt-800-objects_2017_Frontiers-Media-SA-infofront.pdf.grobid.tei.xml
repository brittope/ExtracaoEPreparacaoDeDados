<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main" xml:id="_X2TYnPk">Motivational Objects in Natural Scenes (MONS): A Database of &gt;800 Objects</title>
				<funder ref="#_jgFNbJR">
					<orgName type="full">unknown</orgName>
				</funder>
				<funder ref="#_eMxDV2w">
					<orgName type="full">German Research Foundation (DFG)</orgName>
				</funder>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability  status="unknown">
					<licence/>
				</availability>
				<date type="published" when="2017-09-26">26 September 2017</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Judith</forename><surname>Schomaker</surname></persName>
							<email>judith.schomaker@gmail.com</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Justus Liebig University Giessen</orgName>
								<address>
									<settlement>Giessen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Elias</forename><forename type="middle">M</forename><surname>Rau</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Justus Liebig University Giessen</orgName>
								<address>
									<settlement>Giessen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Wolfgang</forename><surname>Einh√§user</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Institute of Physics</orgName>
								<orgName type="institution">Chemnitz University of Technology</orgName>
								<address>
									<settlement>Chemnitz</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Neurophysics</orgName>
								<orgName type="institution">Philipps University of Marburg</orgName>
								<address>
									<settlement>Marburg</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Bianca</forename><forename type="middle">C</forename><surname>Wittmann</surname></persName>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Justus Liebig University Giessen</orgName>
								<address>
									<settlement>Giessen</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution">Tilburg University</orgName>
								<address>
									<country key="NL">Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">KU Leuven</orgName>
								<address>
									<country key="BE">Belgium</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Raffaella Ricci</orgName>
								<orgName type="institution" key="instit2">University of Turin</orgName>
								<address>
									<country key="IT">Italy</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main" xml:id="_3TV2akJ">Motivational Objects in Natural Scenes (MONS): A Database of &gt;800 Objects</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2017-09-26">26 September 2017</date>
						</imprint>
					</monogr>
					<idno type="MD5">51319E5F32CDCF3F4EF00B1DDA0CE3C1</idno>
					<idno type="DOI">10.3389/fpsyg.2017.01669</idno>
					<note type="submission">This article was submitted to Emotion Science, a section of the journal Frontiers in Psychology Received: 12 August 2016 Accepted: 11 September 2017</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.8.2-SNAPSHOT" ident="GROBID" when="2025-08-26T13:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term xml:id="_4txWvfK">objects</term>
					<term xml:id="_B4jzAGV">scenes</term>
					<term xml:id="_YssRZVg">motivational value</term>
					<term xml:id="_weByA74">arousal</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0" xml:id="_edHtgWE"><p xml:id="_wTkHFgM"><s xml:id="_ZKPSXcc">In daily life, we are surrounded by objects with pre-existing motivational associations.</s><s xml:id="_hKdt7B9">However, these are rarely controlled for in experiments with natural stimuli.</s><s xml:id="_GtWp9FD">Research on natural stimuli would therefore benefit from stimuli with well-defined motivational properties; in turn, such stimuli also open new paths in research on motivation.</s><s xml:id="_w9ugP2d">Here we introduce a database of Motivational Objects in Natural Scenes (MONS).</s><s xml:id="_29aQWk8">The database consists of 107 scenes.</s><s xml:id="_TFAxjmX">Each scene contains 2 to 7 objects placed at approximately equal distance from the scene center.</s><s xml:id="_GCQx3UC">Each scene was photographed creating 3 versions, with one object ("critical object") being replaced to vary the overall motivational value of the scene (appetitive, aversive, and neutral), while maintaining high visual similarity between the three versions.</s><s xml:id="_qtBeHcj">Ratings on motivation, valence, arousal and recognizability were obtained using internet-based questionnaires.</s><s xml:id="_KEER7tu">Since the main objective was to provide stimuli of well-defined motivational value, three motivation scales were used: (1) Desire to own the object; (2) Approach/Avoid; (3) Desire to interact with the object.</s><s xml:id="_9H4Mj9v">Three sets of ratings were obtained in independent sets of observers: for all 805 objects presented on a neutral background, for 321 critical objects presented in their scene context, and for the entire scenes.</s><s xml:id="_DtgqqFT">On the basis of the motivational ratings, objects were subdivided into aversive, neutral, and appetitive categories.</s><s xml:id="_Qv5zrGM">The MONS database will provide a standardized basis for future studies on motivational value under realistic conditions.</s></p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_gRqDkxP">INTRODUCTION</head><p xml:id="_eryzB7q"><s xml:id="_jbEcZGf">When interacting with the world around us, a range of factors guide our behavior.</s><s xml:id="_VQFzVeV">In addition to internal states and drives, actions are also determined by the incentive properties of our environment.</s><s xml:id="_f78qVdZ">Through experience, many objects come to be associated with appetitive or aversive motivational properties that guide our interaction with these objects in daily life.</s><s xml:id="_tbg3xQP">In contrast, research on the effects of motivation on attention or memory commonly employs artificial stimuli for which motivational relevance is learned during the experiment.</s><s xml:id="_VxvrEzZ">Some studies use real objects or scenes <ref type="bibr" target="#b21">(Hickey et al., 2015)</ref>, but pre-existing motivational value is rarely considered.</s><s xml:id="_Xte3WH2">Previous databases of emotional and motivational value generally present decontextualized objects on a blank background, such as food <ref type="bibr" target="#b7">(Blechert et al., 2014;</ref><ref type="bibr" target="#b33">Miccoli et al., 2014)</ref>.</s><s xml:id="_ugHwch9">Research on the neural and behavioral effects of appetitive and aversive motivation, such as investigations of its effects on attention, memory and choice, could therefore benefit from a comprehensive database of the motivational value assigned to everyday objects in more complex scenes.</s></p><p xml:id="_eURX2wY"><s xml:id="_PZQuEsN">Motivational stimuli and internal motivational states serve as inducements to action by affecting the direction, intensity and duration of a set of actions.</s><s xml:id="_4XXzAd9">The most basic and longstanding distinction that characterizes motivated behavior distinguishes actions of approach and avoidance that are elicited by appetitive and aversive factors, respectively <ref type="bibr" target="#b43">(Thorndike, 1911;</ref><ref type="bibr" target="#b45">Watson, 1913;</ref><ref type="bibr" target="#b39">Skinner, 1938;</ref><ref type="bibr" target="#b22">Higgins, 1997)</ref>.</s><s xml:id="_hD4r2a3">Motivation can thus direct actions toward or away from objects associated with high or low subjective utility (see for example <ref type="bibr" target="#b14">Elliot, 2006;</ref><ref type="bibr" target="#b9">Braver et al., 2014)</ref>.</s><s xml:id="_FyVygEA">Although this association suggests that motivational drive is related to the hedonic experience of action outcomes and thus to emotional experience, the two concepts can be distinguished <ref type="bibr" target="#b5">(Berridge and Robinson, 1998)</ref>.</s><s xml:id="_ZUyrWbR">Both humans and non-human animals may display motivated actions in the absence of hedonic reactions to the outcome (referred to as 'liking'), and conversely experience hedonic reactions in the absence of motivational drive (referred to as 'wanting'), and the two states have been suggested to involve different brain systems (for a review, see <ref type="bibr" target="#b3">Berridge, 2015)</ref>.</s><s xml:id="_54Vq4Yx">For research using natural stimuli, it is therefore important to separately control for the motivational drive elicited by objects and object-related emotional reactions.</s><s xml:id="_dB7VQGn">An additional, largely separate aspect is the frequency with which objects are encountered in daily life.</s><s xml:id="_7S5yfNg">Lower frequency may lead to reduced recognizability, which would make the ratings less interpretable.</s></p><p xml:id="_yYvRBdg"><s xml:id="_TEEtpaH">Studies using realistic motivational stimuli have been scarce.</s><s xml:id="_CbzxD7z">Here we introduce a new picture database, Motivational Objects in Natural Scenes (MONS).</s><s xml:id="_P6cYANk">805 objects were taken from newly photographed natural scenes intended for experimental use.</s><s xml:id="_9xhfDyg">Objects have been shown to elicit strong motivational effects in consumer settings (e.g., <ref type="bibr" target="#b15">Elliott, 1998;</ref><ref type="bibr" target="#b38">Seva et al., 2007;</ref><ref type="bibr" target="#b13">Cohen et al., 2008;</ref><ref type="bibr" target="#b0">Alba and Williams, 2013)</ref>, findings that are supported by recent fMRI evidence on product-related decision making (e.g., <ref type="bibr" target="#b25">Knutson et al., 2007;</ref><ref type="bibr" target="#b12">Chib et al., 2009;</ref><ref type="bibr" target="#b29">Levy et al., 2011)</ref>.</s></p><p xml:id="_pKh87D2"><s xml:id="_kskQBaK">These studies and existing databases mostly used isolated objects, motivating the natural-scene database presented here.</s><s xml:id="_7uBjtWn">The term natural scenes is often used to refer to realistic scenes that we could encounter in every-day life <ref type="bibr" target="#b19">(Hart et al., 2013;</ref><ref type="bibr" target="#b31">Marx et al., 2014;</ref><ref type="bibr" target="#b41">Stoll et al., 2015)</ref>.</s><s xml:id="_Wze7Dtr">At the same time, low-level physical properties of a scene influence visual processing and guidance of attention <ref type="bibr" target="#b1">(Awh et al., 2012)</ref>.</s><s xml:id="_hkHjHan">Hence, we aimed to control for low-level visual properties by photographing each scene at least three times, each time replacing one object ("critical object") in the scene to create versions with varying motivational value (see Figure <ref type="figure" target="#fig_0">1</ref> for an example).</s><s xml:id="_UKNC7yk">Although scenes photographed in this way may still look slightly artificial as compared to our typically cluttered environment, they are still composed of real objects.</s><s xml:id="_5RNDjA5">Indeed, such scenes with nicely arranged objects are actually quite common in everyday life, for example in shop displays.</s><s xml:id="_PxbmMAs">The scene creation procedure also allowed us to maintain a high level of visual similarity between scenes and objects while varying their motivational properties.</s><s xml:id="_rsCMR6F">In addition to the critical object, each scene contains one to six additional neutral objects.</s><s xml:id="_5T3AcYt">On the basis of the motivational ratings, the images were categorized as appetitive, neutral, and aversive.</s></p><p xml:id="_yFcSeTf"><s xml:id="_6xarY9c">We acquired ratings for the objects isolated from the scenes presented on a white background using online questionnaires and separate ratings for the critical objects presented in their scene context.</s><s xml:id="_vdWAE2e">Each object was rated on three scales intended to measure different aspects of motivation and three scales measuring possible confounding factors.</s><s xml:id="_kBnSdZh">In addition, we obtained ratings for the entire scenes.</s></p><p xml:id="_ugFCfP7"><s xml:id="_hV9ZR6n">Because of the diversity of objects in the database, we designed three scales to capture the main aspects of motivation.</s><s xml:id="_g5qV95K">Although the three scales were expected to measure a single dimensionmotivation -we reasoned that the motivational properties of some objects might be captured better by only one or two of the scales.</s><s xml:id="_pGqt542">The action component that defines motivation was therefore measured by two scales assessing the wish to interact with an object (Interaction scale) and whether to approach or avoid (Approach/Avoid scale) the object.</s><s xml:id="_uPhKCAZ">Note that the term interaction may be broadly interpreted, reflecting the typical action associated with an object (e.g., eating in the case of food, and viewing in the case of a painting).</s><s xml:id="_2jaWG8J">Although the two scales overlap in many cases, ratings may differ for some objects (for example, one may not wish to interact with a musical instrument if one cannot play it, but one may wish to approach it to hear others play).</s><s xml:id="_WZNaKqa">Related to this action component of motivation is the distinction between objects that are typically associated with passive or active behavior.</s><s xml:id="_xhsBhu8">A clear perception-action link, also referred to as affordance, will probably lead to approach and interaction behavior <ref type="bibr" target="#b17">(Gibson, 1979)</ref>.</s><s xml:id="_n2kJy9S">No affordance scale was included in order to keep the number of ratings manageable for subjects, but our interaction and approach/avoidance scales may have partly captured this concept.</s></p><p xml:id="_ExzEsBV"><s xml:id="_sw6z5tk">The third motivational scale addressed the component of wanting <ref type="bibr" target="#b6">(Berridge et al., 2009)</ref> by measuring how much participants desired to own the object (Desire to Own scale).</s><s xml:id="_7DemGQP">For many objects, this scale will be correlated with the other two scales.</s><s xml:id="_UvWekGc">However, in some cases the scales may differ (e.g., one may wish to interact with a park bench by sitting on it, but may not wish to own it; see Table <ref type="table" target="#tab_0">1</ref> for all scale questions).</s></p><p xml:id="_dmGbWre"><s xml:id="_ZBr5TZh">We aimed to control for the affective properties of the objects.</s><s xml:id="_y5qGMkV">The selected objects were intended to vary more widely in motivational value than in their emotional impact.</s><s xml:id="_VkFuR2M">Widely accepted dimensional theories of emotion generally divide the affective space into the two dimensions valence and arousal <ref type="bibr" target="#b36">(Russell, 1980;</ref><ref type="bibr" target="#b26">Lang et al., 2008)</ref>.</s><s xml:id="_cC2wpcP">Two scales measuring Valence and Arousal were therefore included in the ratings.</s><s xml:id="_5TWyn8k">An additional scale was included to control for recognizability of the objects (see for example <ref type="bibr" target="#b30">Martin et al., 2001)</ref>.</s></p><p xml:id="_NxtV6u6"><s xml:id="_h7eDNw6">The purpose of the current database is to provide vision researchers and cognitive neuroscientists with a controlled stimulus set consisting of realistic natural scenes and everyday objects.</s><s xml:id="_bde5qxg">The database will allow scientists to use stimuli with controlled ratings on motivation, valence, arousal, or recognizability when one of these dimensions is relevant in their experiment.</s><s xml:id="_JPbaPHA">The database can be used to select motivationally neutral stimuli, for example to exclude motivational influences in memory tasks, as well as to select appetitive or aversive stimuli, for example in studies of visual attention.</s><s xml:id="_NjrRgye">Vision scientists may be especially interested in our natural scene set, as the scenes were controlled in terms of visual characteristics (see above), and we provide exact object locations within the scenes.</s></p><p xml:id="_kNHAu2w"><s xml:id="_4r78Cm8">To support a range of experimental uses, we collected ratings on the isolated objects, on the objects in the scenes and on the scenes as a whole.</s><s xml:id="_sugZ6sz">For each set of ratings, we conducted a principal component analysis.</s><s xml:id="_h6XQrHY">Please note: Throughout the text, we will refer to the motivational categories as appetitive, neutral and aversive, in contrast to the valence ratings, which we will refer to as positive and negative or low and high in valence.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9nDgJen">GENERAL EXPERIMENTAL PROCEDURES Stimulus Creation</head><p xml:id="_RxZ8PSP"><s xml:id="_mBjZEQU">For this database, motivational and neutral objects in natural scenes were photographed at least three times, each time replacing one object ("critical object") that was intended to vary in motivational value.</s><s xml:id="_5n5pwSe">The scenes were controlled such that objects were mostly decentralized, objects only overlapped minimally and scenes contained between 2 and 7 objects.</s><s xml:id="_K5ejhrh">Each triad of scenes was photographed from the same visual angle, keeping lighting conditions as similar as possible.</s><s xml:id="_WM5ez7q">In each version of a triad of scenes one object varying in intended motivational value was replaced, aiming to create versions that differed in terms of motivational value.</s><s xml:id="_u9yfSBE">All other objects in the scenes were intended to be neutral.</s><s xml:id="_Cx6zydj">We selected objects to vary on motivational value, and later subdivided the stimuli into motivational categories on basis of the ratings.</s><s xml:id="_896jZZQ">We did not include animate objects, objects with human face depictions, or objects with large texts, as these aspects are all known to draw attention <ref type="bibr" target="#b11">(Cerf et al., 2008</ref><ref type="bibr" target="#b10">(Cerf et al., , 2009))</ref>, irrespective of motivation.</s><s xml:id="_AZBPQ34">Small texts were later removed using image manipulation software (see below).</s></p><p xml:id="_RdyzeXa"><s xml:id="_y9ktWTq">Part I reports ratings of all objects in isolation (cut out of the scenes) on three scales intended to measure motivation (Interaction, Desire to Own, and Approach/Avoid), two emotional scales measuring valence (negative to positive) and arousal (calming to exciting), and a scale measuring recognizability (unrecognizable to familiar).</s><s xml:id="_dqWQAYB">Part II reports ratings of the critical objects in the scenes on all scales except Recognizability, as we expected that the objects would be more easily recognized in their original context.</s><s xml:id="_GAYCfsv">Part III reports ratings of the entire scenes on motivation (Approach/Avoid, Spending Time and Exploration), arousal and valence.</s><s xml:id="_ZXeFEGB">For some scenes, more than three versions were created, but only three were selected for the scene ratings, in order to create balanced questionnaire versions (Part III).</s><s xml:id="_xVGpUPZ">Some objects were extracted from scenes that were not included in the final version of the database.</s><s xml:id="_QyJJTUF">For completeness, these unrated scenes can be found in the online database (scene numbers &gt; 107).</s></p><p xml:id="_DxNKBHC"><s xml:id="_SY6PpYM">In addition to the 107 triads of scenes eventually used in Parts II (objects in scenes ratings) and III (scene ratings), an additional 40 critical objects were presented in Part I, yielding a total of 805 objects to be investigated in isolation.</s><s xml:id="_CfZauHr">Objects were cut out from the photographed scenes and all legible text was removed using the GNU Image Manipulation Program 2<ref type="foot" target="#foot_2">foot_2</ref> .</s><s xml:id="_MyGgycQ">The cutout objects are presented on a white background and rescaled to fit in a 1000 pixel √ó 1000 pixel image preserving aspect ratio.</s></p><p xml:id="_ZwBAQ8F"><s xml:id="_9rY3SJS">To verify that the background objects, which were intended to be neutral, are not perceived as strongly motivational, we quantified their deviance from neutrality.</s><s xml:id="_62cZ2gR">A non-neutrality measure (also reported in the online documentation) was created by summing over the absolute difference of ratings for neutral, non-critical objects in the scene when these deviated from the neutral range (3.5-4.5).</s><s xml:id="_7mpzBz7">To support a range of experimental uses of the database, separate deviance measures were calculated for the mean motivation, valence and arousal scales.</s></p><p xml:id="_UUSxAaN"><s xml:id="_eMNfuA5">All objects, scenes, and rating data can be downloaded free of charge at doi: 10.5281/zenodo.883110.</s><s xml:id="_zzbjg6r">The exact locations of the objects in the scenes are included in the form of coordinates of bounding boxes containing the objects.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_XkFebSX">Participant Recruitment</head><p xml:id="_DxKfhUB"><s xml:id="_4y8GxB6">Inclusion criteria were age 18-45 years, no history of neurological or psychiatric illnesses (as subjectively reported).</s><s xml:id="_C6QmUTq">Only participants reporting to have good or excellent English skills could participate.</s><s xml:id="_DUUd5vj">The study was approved by the ethics committee of the Department of Psychology and Sports Science at the Justus Liebig University, Giessen.</s><s xml:id="_E76NTPd">All participants gave informed consent by checking a box.</s><s xml:id="_5Vruuu6">Respondents were recruited</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_UjZ2akw">PART I: RATINGS OF OBJECTS IN ISOLATION Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cv8mT65">Participants</head><p xml:id="_cJNCea7"><s xml:id="_2F8vbWE">The questionnaire was started by 904 volunteers, of whom 439 were eligible based on the inclusion criteria and filled in the questionnaire.</s><s xml:id="_qzB2tZE">After reading the study information on the first pages of the questionnaire, 51 participants decided to not participate and did not give informed consent by checking the box.</s><s xml:id="_ZzjhfZh">Also, our inclusion criteria were quite strict.</s><s xml:id="_RC769Ab">The age range of 18-45 years led to the exclusion of 31 participants.</s><s xml:id="_ZdvjH9H">In addition, we excluded all participants with a self-reported history of or a current psychiatric illness (n = 58).</s><s xml:id="_4wUYQ5U">The inclusion on basis of English skills also led to the exclusion of a relatively large number of subjects (n = 152), as we promoted our questionnaire among undergraduate students in Germany.</s><s xml:id="_dXyV2FN">Also, non-disclosure on any of these inclusion criteria led to exclusion (n = 173).</s><s xml:id="_CAYFc5d">Non-eligible volunteers were directed to the end of the questionnaire and could not fill in the questionnaire.</s><s xml:id="_ANag7EK">Eight participants were excluded because of poor data quality (&gt;80 min to complete the questionnaire or no variation in answers).</s><s xml:id="_CDzBGTH">Four hundred and thirty-one participants [257 female; age 18-45 years, mean = 25.6, standard deviation = 4.6; highest completed education: Range from Secondary/High school (level 2) to Doctorate/Professional degree (level 6), median = Bachelor degree (level 4)] were included in the analyses.</s><s xml:id="_uEyFDp5">Each participant filled in one of 12 versions of the questionnaire consisting of randomly chosen unique objects.</s><s xml:id="_abw3PB4">The number of participants and participant details per version of the questionnaire can be found in Table <ref type="table" target="#tab_1">2</ref>. Data from unfinished questionnaires were included in the analyses.</s><s xml:id="_5gsCS45">Twelve versions of the questionnaire were created, each containing 71 objects, except for the eleventh and twelfth questionnaires, which consisted of 45 and 50 objects, respectively.</s><s xml:id="_97dxqwe">In total, ratings were obtained for 805 objects.</s><s xml:id="_jyXwp5u">For presentation in the questionnaire, the images were further rescaled to 300 pixels √ó 300 pixels.</s><s xml:id="_msWRY9y">All objects were rated on six 7-point Likert scales.</s><s xml:id="_2gmsSSG">To the authors' knowledge, no scales currently exist that aim to measure motivational value of natural scenes or realistic objects from a range of categories (food and non-food), therefore we constructed three scales for this purpose: (1) Desire to Own ("How much would you like to own this object?");</s><s xml:id="_Akg6WYC">(2) Approach/Avoid ("Do you want to approach or avoid the object?");</s><s xml:id="_qxaZNvH">(3) Interaction ("How much would you like to interact with the object?").</s><s xml:id="_mH3xJuR">The scales went from "Not at all" to "Very much."</s><s xml:id="_DMgdXDx">The other scales measured (4) Arousal ("Does this object make you calm or aroused?") from "Calm" to "Aroused"; (5) Valence ("Does this object elicit any positive or negative emotions?") from "Negative" to "Positive, " and ( <ref type="formula">6</ref>) Recognizability ("Do you recognize the object?") from "Not at all" to "Very Familiar."</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_S3zayrh">Analyses</head><p xml:id="_Wfc4VA6"><s xml:id="_pz7vkHN">To investigate how the different scales (Desire to Own, Approach/Avoid, Interact, Arousal, Valence, and Recognizability) relate, we performed a principal component analysis (PCA).</s><s xml:id="_5Cq7KeZ">To reduce possible effects of individual bias, prior to the analyses described in this section (ICC and PCA), ratings were z-transformed per participant, separately for each scale (Desire to Own, Approach/Avoid, Interact, Arousal, Valence, and Recognizability).</s><s xml:id="_XY2w9NC">To check whether objects were similarly rated by the different raters who used the same questionnaire, we calculated the intraclass correlation coefficient (ICC) separately for each scale, using the R package R3.1.0</s><s xml:id="_xtJd89C">(version 0.84; <ref type="bibr" target="#b35">R Core Team, 2014)</ref>.</s><s xml:id="_eeC6G3F">For all of the 72 combinations of questionnaire ( <ref type="formula">12</ref>) and scale (6), the ICC was significantly larger than 0 (range: 0.024-0.308;</s><s xml:id="_hNFa396">all ps &lt; 0.003).</s><s xml:id="_xw7wK3v">Therefore, data for subsequent analyses was aggregated over all raters for the principal component analysis (PCA).</s><s xml:id="_N7KuJuq">After the first rotation, the number of components to extract was determined using visual inspection of the scree plot of the eigenvalues per scale.</s><s xml:id="_Az3M7zs">In the second step of the PCA, a varimax rotation was used <ref type="bibr" target="#b24">(Kaiser, 1958)</ref>.</s><s xml:id="_4gF3Pzr">Since results from the PCA showed that the three motivational scales (Desire to Own, Approach/Avoid, and Interaction) correlated strongly, these scales were taken together in further analyses by calculating the mean motivation rating over these scales.</s><s xml:id="_cB4NG6U">Although valence also loaded highly on the same factor, it was not taken together with the motivational scales as the current database focuses on motivation and databases with emotional stimuli are already available (e.g., IAPS; <ref type="bibr" target="#b26">Lang et al., 2008)</ref>.</s></p><p xml:id="_HyQJ6P3"><s xml:id="_aeWCUYm">Post hoc we created three categories of motivational objects.</s><s xml:id="_xSBp24u">Objects for which the mean motivational rating was ‚â§3.5 were categorized as aversive, objects rated 3.5-4.5 were categorized as neutral, and objects rated ‚â•4.5 were categorized as appetitive (see Table <ref type="table" target="#tab_2">3</ref> for details on the post hoc motivational categories per scale).</s><s xml:id="_HCd5t4T">As this post hoc division created categories unequal in size, we also provide a division in quintiles in the online documentation files.</s><s xml:id="_W7pzwRV">The division in quintiles resulted in two levels of aversive (I and II), one level of neutral (III), and two levels of appetitive (IV and V) categories, and may be used if a more fine-grained division in motivational categories is preferred.</s></p><p xml:id="_5MWyp3u"><s xml:id="_TGW59TH">Since the objects were cut out of pictures of scenes, the critical objects were not always in focus, and sometimes partly occluded, possibly affecting the image quality.</s><s xml:id="_QRBpnM6">As image quality might have affected the ratings, we also obtained subjective quality ratings ("Please rate the image quality") on a 7-point scale from "Very poor" to "Excellent."</s><s xml:id="_jxwZvmK">To obtain a general quality rating, no concrete instructions were given concerning the rating criteria.</s><s xml:id="_qjTCVkz">Two quality questionnaires were composed, one with 400 and the other with 405 objects, that were filled out by new participants.</s><s xml:id="_cNzAJFW">As subjective image quality ratings may be affected by motivational modulation, we additionally calculated an objective image quality assessment (IQA; <ref type="bibr" target="#b34">Mittal et al., 2013)</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_cPKNE9q">Results</head><p xml:id="_3ENWhaM"><s xml:id="_fu3mFuS">More females (N = 257) than males (N = 174) filled in the questionnaire, and the ratio of female/male participants was different for the different versions, œá 2 (11, N = 431) = 24.83,</s><s xml:id="_F78xYHU">p = 0.010.</s><s xml:id="_7RnaEjK">In the online documentation, we report mean ratings for males and females separately, as well as the mean ratings across gender.</s><s xml:id="_tDDWtfH">Details on the post hoc motivational object categories can be found in Table <ref type="table" target="#tab_2">3</ref>.</s><s xml:id="_wYWM8Kf">In total, 136 objects were categorized as aversive (mean motivational rating ‚â§ 3.5), 385 as neutral (mean motivational rating 3.5-4.5),</s><s xml:id="_z8UaFhM">and 284 as appetitive (mean motivational rating &gt;4.5), making a total of 805 objects.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_hZu24ae">PCA Analyses</head><p xml:id="_dDCu8dq"><s xml:id="_8cswedE">Ratings were collapsed over raters for the PCA analyses.</s></p><p xml:id="_Vb8TtnG"><s xml:id="_QBghdKs">A PCA analysis was performed on the z-transformed ratings to investigate the underlying structure of the six scales.</s><s xml:id="_yyQwGjH">Visual inspection of the scree plot after the initial rotation showed that the curve dropped off at two points (after component 1 from eigenvalue 3.28 to 1.07 for component 2, and from component 3 to 4 from 0.83 to 0.47).</s><s xml:id="_emZCQ4g">Since the eigenvalues of component 2 and 3 were larger than or close to 1 (1.07 and 0.83, respectively), and the eigenvalue for component 4 dropped substantially (0.46), three components were extracted in the second step of the analysis.</s><s xml:id="_82G7rAT">Varimax rotation was performed for three extracted components.</s><s xml:id="_fJf8RWx">All three motivational scales (Desire to Own, Approach/Avoid, Interaction) and Valence loaded highly on component 1, which explained 54.62% of the variance.</s><s xml:id="_5y7C5kf">Arousal loaded highly on component 2, explaining 17.80% of the variance (72.49% cumulatively).</s><s xml:id="_XfwaS2v">Recognizability loaded highly on component 3, explaining 13.77% of the variance (86.27% cumulatively; see Figure <ref type="figure" target="#fig_2">2A</ref> for the component loadings for each scale), confirming their independence from the motivational scales.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_jbkjnPy">Image Quality</head><p xml:id="_3zhyDCX"><s xml:id="_5djhfGr">Thirty (24 female; age range = 18-39; age mean = 23.0;</s><s xml:id="_bD9NwvU">education range = 2-4; education median = 3) and 22 (18 female; age range = 18-31; age mean = 23.2;</s><s xml:id="_QbguaXM">education range = 2-5; education median = 3) newly recruited participants completed the two image quality questionnaires.</s><s xml:id="_eE2dDNG">Motivational category affected the quality ratings, F(2,802) = 3.60, p &lt; 0.028, Œ∑ 2 = 0.01.</s><s xml:id="_8FQyFFD">Post hoc comparisons with Bonferroni correction for multiple comparisons were performed to compare the motivational categories.</s><s xml:id="_dPUYjNB">Appetitive objects received higher ratings (mean = 3.87; SD = 0.98) than aversive objects (mean = 3.61; SD = 1.02), t(418) = 2.52, p =0.012, and subjective quality for appetitive and neutral objects did not differ (mean = 3.73; SD = 0.95), t(667) = 1.81, p = 0.071.</s><s xml:id="_6M2ZRR5">Quality ratings were similar for aversive and neutral objects (p = 0.196).</s><s xml:id="_6qaaMV7">Motivational category also affected the objective image quality assessment, F(2,802) = 6.61, p = 0.001, Œ∑ 2 = 0.002.</s><s xml:id="_ct7Srt3">In line with the subjective ratings, appetitive objects were calculated as being of higher quality (mean = 7.58; SD = 2.74) than aversive objects (mean = 8.46; SD = 3.66), t(418) = 2.75, p = 0.006 (note, higher image quality assessment values reflect lower quality).</s><s xml:id="_X2hhrZw">In addition, neutral objects were estimated to have higher quality than aversive objects (mean = 7.53; SD = 2.14), t(519) = 3.56, To further investigate whether the quality ratings were affected by other factors, we calculated a correlation between the quality measures and the recognizability rating.</s><s xml:id="_k3U3k47">The subjective ratings showed a positive correlation with recognizability, r(805) = 0.12, p = 0.001, but no correlation was found for the objective quality measure (p = 0.401), suggesting that recognizability affected subjective perception of quality.</s><s xml:id="_mvUhnad">Both subjective and objective quality measures can be found in the object ratings documentation file.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_kde8W4A">PART II: RATINGS OF OBJECTS IN SCENES Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_X944Rq7">Participants</head><p xml:id="_M2qVd44"><s xml:id="_jjZX7bz">The questionnaire was started by 510 volunteers, of whom 195 eligible participants (137 female; age 18-45 years, mean = 24.3,</s><s xml:id="_KMjUCmA">standard deviation = 5.0; education range: 1-6; education median = 3) filled it in and were included in the analyses.</s><s xml:id="_pm94Wb8">Each participant filled in one or two of six versions of the questionnaire including unique versions of the triads of scenes containing one relevant object, such that the same scene was not repeated for a particular participant.</s><s xml:id="_CC28Myp">Participant details per version of the questionnaire can be found in Table <ref type="table" target="#tab_1">2</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_Gz9seub">Procedure</head><p xml:id="_2rrgZCH"><s xml:id="_WfpZBh3">Ratings were obtained for the critical objects; that is, for the object in a scene that is varied across the triad.</s><s xml:id="_ZHWTuBy">In contrast to the first object-rating experiment, objects were now presented in the scenes in which they were originally photographed rather than in isolation.</s><s xml:id="_pYAHV3J">The relevant object that required rating was highlighted by a box with black/white dashed lines.</s><s xml:id="_6BUetdN">Participants filled in up to two versions of the questionnaire that each contained 60 (first three questionnaires) or 56 objects (last three versions).</s><s xml:id="_RwAhD85">In total, ratings were obtained for 348 unique objects in 116 different scenes.</s><s xml:id="_T2d6kH4">Nine scenes were excluded due to poor image quality, resulting in a total of 107 scenes that were included in the analyses.</s><s xml:id="_5STNA2A">The scenes were all presented on a white background and rescaled to 750 pixels √ó 562 pixels.</s><s xml:id="_4vVMNBf">The objects in the scenes were rated on the same scales as the objects in isolation except for the Recognizability scale, as we expected that the objects would be more easily recognized in their original context.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_YPp3aRb">Analyses</head><p xml:id="_9qMFQbf"><s xml:id="_5QtM5KE">To validate findings from the objects-in-isolation ratings, a PCA was performed using the same procedures.</s><s xml:id="_xkVGeVA">Since results from the PCA again showed that the three motivational scales (Desire to Own, Approach/Avoid, and Interaction) correlated strongly, these scales were taken together in further analyses as in Part I. To confirm that the ratings for the objects in isolation were not affected by reduced recognizability due to out of context presentation, nor ratings for the objects in scenes affected by their context, correlations were calculated between the ratings per scale.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_hCSxwMg">Results</head><p xml:id="_BMx5NE3"><s xml:id="_v44DYna">Table <ref type="table" target="#tab_3">4</ref> shows details about the post hoc motivational categories per scale.</s><s xml:id="_cG6eaPj">In total, 104 objects were categorized as aversive (mean motivational rating ‚â§ 3.5), 127 as neutral (mean motivational rating 3.5-4.5),</s><s xml:id="_JEzgEec">and 90 as appetitive (mean motivational rating &gt; 4.5), making a total of 321 objects in scenes.</s><s xml:id="_cRCfSFQ">Note that the total number of objects is lower than in Part I, as ratings were only obtained for the 'critical' objects, that is, the objects that were replaced in the scene and that were intended to vary in motivational value.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_4wBE32u">PCA Analyses</head><p xml:id="_ETta25Z"><s xml:id="_J6GvUtX">Visual inspection of the scree plot after the initial rotation showed that the curve again dropped off at two points (after component 1 from eigenvalue 3.47 to 0.98 for component 2, and from component 2 to 3 from 0.98 to 0.42).</s><s xml:id="_2JQQE8E">Using the same criteria as for the ratings of objects in isolation, we chose to extract two components in the second step of the analysis.</s><s xml:id="_tDr9EjB">Varimax rotation replicated the findings for isolated objects, as the three motivational scales (Desire to Own, Approach/Avoid, Interaction) and Valence loaded highly on component 1, explaining 69.38% of the variance.</s><s xml:id="_J7ctEZy">Arousal loaded highly on component 2, explaining 19.54% of the variance (88.93% cumulatively; see Figure <ref type="figure" target="#fig_2">2B</ref> for the component loadings for each scale), confirming its independence from the motivational scales.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_7teHE6F">Correlations between Ratings for Objects in Isolation and Objects in Scenes</head><p xml:id="_32gMq7y"><s xml:id="_ZPTsk5v">For the motivational scales Approach/Avoid, Interaction, and Desire to Own, positive correlations were observed between the ratings for the objects in the isolation and in the scenes: r(321) = 0.66, p &lt; 0.001, r(321) = 0.71, p &lt; 0.001, and r(321) = 0.68, p &lt; 0.001, respectively.</s><s xml:id="_7rv9eJn">A positive correlation was also found for the valence ratings, r(321) = 0.59, p &lt; 0.001 and arousal ratings, r(321) = 0.41, p = 0.001.</s><s xml:id="_hGdgWaR">These correlations are depicted in Figure <ref type="figure" target="#fig_3">3</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_rD7SpfY">PART III: SCENE RATINGS</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_2hrKWaV">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9Mn2ACG">Participants</head><p xml:id="_m5BZ9nw"><s xml:id="_nUGYnpu">The questionnaire was started by 426 participants, of whom 164 were eligible.</s><s xml:id="_DtnDaxk">One participant was excluded because of a report of technical problems.</s><s xml:id="_RSZvdft">163 participants were included in the analysis (121 female; age 18-45 years, mean = 23.9, standard deviation = 5.3; highest completed education range from 2 to 6; education median = 4).</s><s xml:id="_pGreMYC">Each participant filled in one of 6 versions of the questionnaire consisting of 116 scenes.</s><s xml:id="_sDTWTxD">Participant details per questionnaire version can be found in Table <ref type="table" target="#tab_1">2</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_c9vnFsq">Procedure</head><p xml:id="_6TKBUKJ"><s xml:id="_va2euN6">Ratings were obtained for the entire scenes rather than specific objects.</s><s xml:id="_E6bKBpK">Six versions of the questionnaire were created, the first three each containing 60 scenes, and the last three containing 56 scenes.</s><s xml:id="_DHVYr5M">Ratings were obtained for three versions of 116 scenes (348 in total; but note that nine triads were excluded due to poor image quality, resulting in a total of 321 scenes).</s><s xml:id="_62WZMYh">Each participant did not rate more than one version of the same scene.</s></p><p xml:id="_5XTxTwY"><s xml:id="_TMMnzVw">The scene size at presentation was 750 pixels √ó 562 pixels.</s><s xml:id="_4n7Cq8t">All scenes were rated on five 7-point Likert scales.</s><s xml:id="_Gyj6HrA">For the ratings of the entire scenes, we could not use the same set of scales as for the objects because interacting with an object (Interaction), owning an object (Desire to Own) and being familiar with an object (Recognizability) do not directly transfer to whole scenes.</s><s xml:id="_FKxe2j4">Again, three scales related to motivational value were created: Approach/Avoid, Spending Time and Exploration.</s><s xml:id="_YcfmGrB">The last two were intended to replace Interaction.</s><s xml:id="_ngwtA68">The other scales measured Arousal and Valence.</s><s xml:id="_vMAsDC7">See Table <ref type="table" target="#tab_0">1</ref> for the exact questions per scale.</s><s xml:id="_NGXKw8E">Scenes were subdivided post hoc into motivational categories on basis of the motivational ratings for that scene (collapsing across Exploration, Approach/Avoid and Spending Time, as these were found to load on the same PCA component as expected).</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_wGtvZ9y">Analyses</head><p xml:id="_JEpfRF4"><s xml:id="_kKtepgj">To investigate how the different scales (Approach/Avoid, Spending Time, Exploration, Arousal, and Valence) relate, we again performed a PCA, following the same procedures as for the objects.</s><s xml:id="_VZjzjDE">The PCA results showed that Exploration, Approach/Avoid and Spending Time correlated strongly.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_XEjwBK9">Results</head><p xml:id="_rAVQTDv"><s xml:id="_7JvEtuS">Although the database was created to obtain motivation ratings for specific everyday objects, we also obtained ratings for the scenes to provide fully controlled items for use in a range of experimental settings.</s><s xml:id="_htjc7Tt">The images were not created with the aim of making the whole scenes motivational; however, we expected that the scene ratings would be affected by the motivational value of the critical object.</s><s xml:id="_NQDdZbB">Again, we divided the scenes post hoc into aversive, neutral, and appetitive based on the mean motivational ratings.</s><s xml:id="_ptk7bX7">For this, the motivational scales Approach/Avoid, Exploration, and Spending Time were used as these scales loaded on one PCA factor.</s></p><p xml:id="_2nCmFgc"><s xml:id="_MpBXjKU">Table <ref type="table" target="#tab_4">5</ref> shows the details for the motivational categories for the different scales.</s><s xml:id="_mgBa9V4">In total, 52 scenes were categorized as aversive (mean motivational rating ‚â§ 3.5), 218 as neutral (mean motivational rating 3.5-4.5),</s><s xml:id="_6ZHN763">and 51 as appetitive (mean motivational rating &gt; 4.5), making a total of 321 scenes.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_SEcjKW3">PCA Analyses</head><p xml:id="_7BJQfJm"><s xml:id="_JEfrFxh">A PCA analysis was performed for the scene ratings using the same procedures as for the objects.</s><s xml:id="_YMt2Uhe">The scree plot dropped off at two points, after component 1 going from an eigenvalue of 2.83 to 0.94 for component 2, and after component 3 to 4, going from an eigenvalue of 0.66 to 0.37.</s><s xml:id="_68Bd7ac">Using the same criteria as for the previous PCA analyses, three components were included in the Varimax rotation.</s><s xml:id="_ZTmcMSS">Approach/Avoid, Exploration, and Spending Time loaded highly on the first component, explaining 56.47% of the variance.</s><s xml:id="_86npnhg">Therefore, these scales were used to subdivide the scenes in terms of motivation (aversive, neutral, and appetitive).</s><s xml:id="_H6ayQBS">Valence and to a lesser extent Approach/Avoid loaded highly on component 2, explaining an additional 18.86% (75.33 cumulatively), while Arousal loaded highly on component 3, explaining 11.15% of the variance (86.45% cumulatively).</s><s xml:id="_UaUv5D8">See Figure <ref type="figure" target="#fig_2">2C</ref> for the component loadings for each scale.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_TrDFvYa">Correlations between Object Ratings and Scene Ratings</head><p xml:id="_mbawgEs"><s xml:id="_SfERdyk">To check whether the scene ratings reflected the motivational value of the objects in them, we correlated the mean approach/avoid rating of all objects in a scene with its general approach/avoid scene rating.</s><s xml:id="_URzRTt7">This scale was selected, as -unlike for the other scales -the instruction in object and scene rating was most similar.</s><s xml:id="_T4GfkR8">These mean object ratings per scene can be found in the mean object ratings file of the database.</s><s xml:id="_pD94wVn">A positive correlation was observed, r(321) = 0.22, p &lt; 0.001, suggesting that the scene ratings indeed reflect the motivational value of the depicted objects.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_2JJJzQv">DISCUSSION</head><p xml:id="_zmSC6Vz"><s xml:id="_dfyNN5g">The present study introduces MONS, a standardized database of natural appetitive, aversive and neutral objects and scenes.</s><s xml:id="_Gg82Ayu">For this purpose, motivational and neutral objects in natural scenes were photographed at least three times, each time replacing one critical object varying in motivational value.</s><s xml:id="_yXpgvqj">All objects were rated in isolation (cut out of the scenes), and the critical objects were additionally rated in the scenes on three scales intended to measure motivation (Interaction, Desire to Own, and Approach/Avoid) and two additional scales measuring valence (negative to positive) and arousal (calming to exciting).</s><s xml:id="_Gya2jJN">In addition, the objects in isolation were also rated on recognizability (novel to familiar).</s><s xml:id="_F64Gj6j">Finally, ratings were obtained for the entire scenes measuring motivation (Approach/Avoid, Spending Time and Exploration), Arousal and Valence.</s><s xml:id="_57wEnet">All ratings were subjected to separate PCAs for objects in isolation, objects in scenes, and scenes.</s><s xml:id="_cWzzGGT">As expected, Arousal measured independent constructs for all ratings.</s><s xml:id="_QZrwJ7M">Recognizability ratings, which could only be obtained for the objects in isolation, were also confirmed to be independent of the other scales.</s><s xml:id="_Hq2Pwhx">As predicted, for both types of object ratings the three motivational scales all loaded highly on one component, indicating that they measure a single underlying construct, presumably motivational value.</s><s xml:id="_n2KXyeD">Similarly, all motivational scales (Approach/Avoid, Exploration, and Spending Time) for the scene ratings loaded highly on one component.</s></p><p xml:id="_jVdNjFV"><s xml:id="_abVGUt4">Valence, however, also loaded strongly on this component in both object rating experiments, and loaded highly on a component on which the motivational Approach/Avoid scale also loaded highly in the scene rating experiment, suggesting that motivation covaried with the affective reactions elicited by the objects and scenes.</s><s xml:id="_caBaP7R">This conflation of valence and motivation is not unexpected, as motivational drive is related to the hedonic experience of action outcomes and thus to emotional experience.</s><s xml:id="_gsdbJzr">Nonetheless, the two concepts can be distinguished.</s><s xml:id="_YGkNRz4">Valence is more strongly linked to 'liking' and 'disliking, ' whereas motivation is more strongly associated with 'wanting' <ref type="bibr" target="#b4">(Berridge, 2009;</ref><ref type="bibr" target="#b6">Berridge et al., 2009)</ref>.</s><s xml:id="_e4ruMhH">Previous studies indicate that objects can elicit purchase motivation (e.g., <ref type="bibr" target="#b15">Elliott, 1998;</ref><ref type="bibr" target="#b38">Seva et al., 2007;</ref><ref type="bibr" target="#b13">Cohen et al., 2008;</ref><ref type="bibr" target="#b0">Alba and Williams, 2013)</ref>, mediated on a neural level by the motivational system <ref type="bibr" target="#b25">(Knutson et al., 2007;</ref><ref type="bibr" target="#b12">Chib et al., 2009;</ref><ref type="bibr" target="#b29">Levy et al., 2011)</ref>.</s><s xml:id="_4p7Z6aU">The current confound between motivational ratings and valence may be a natural consequence of the connection between emotion and motivation in the real world.</s><s xml:id="_6F6cRVU">However, this association was mostly found in the PCA and is only weakly reflected in the category means, where both aversive and neutral motivational objects were rated in the neutral range on valence and appetitive objects were rated as only slightly above the neutral range on valence.</s><s xml:id="_3qJduMq">Moreover, although there was a general link between valence and motivation, individual objects deviated from this general pattern.</s><s xml:id="_puJ9PAm">Researchers interested in separating the effects of valence and motivation could therefore select those images in which valence and motivation ratings differed the most.</s><s xml:id="_rFy2M7b">For example, a medicine bottle, bag of cat litter and banana peel were rated as neutral on valence, but quite aversively on motivation.</s><s xml:id="_MnnKVz6">Vice versa, a kitchen knife, toilet paper and an umbrella were rated quite low on valence, but rather high on motivation.</s><s xml:id="_M3M2S76">These differences demonstrate that affective impact and motivational drive can be distinguished for everyday objects.</s></p><p xml:id="_H4EkCfr"><s xml:id="_RR3xFjy">We also addressed the possibility that the ratings were affected by image quality.</s><s xml:id="_f4vFpxs">Both subjective quality reports and objective quality assessment measures showed that the appetitive objects have a higher quality than the aversive objects.</s><s xml:id="_hunpfEa">Possibly, the quality of the appetitive objects was indeed coincidentally higher, however, it is also possible that motivation affected the quality ratings, maybe through an attentional mechanism.</s><s xml:id="_sCaqFYa">Another possibility is that recognizability affected the subjective quality ratings, as a positive correlation between recognizability and the subjective quality ratings, but not the objective quality assessment was found.</s><s xml:id="_sBgC3T6">Maybe participants based their quality estimate partly on whether they recognized the object.</s><s xml:id="_NDkQbar">Users of the database may want to use either the quality or recognizability measures when selecting images for their research, or include these measures in their analyses.</s><s xml:id="_U889ra5">The object ratings were not strongly affected by the presentation of the objects in isolation or in the scenes, supported by the consistent PCA results and by significant correlations between object ratings in isolation and object ratings in the scenes.</s><s xml:id="_9FN2Qtf">Even though we controlled for the visual features when creating the scenes, the objects' visual characteristics are not constant; this is an inevitable consequence of using realistic objects and scenes.</s><s xml:id="_r5T4Ysk">Some triads also differ slightly in perspective or lighting.</s><s xml:id="_jZxch4G">One measure to control for such low-level features in future studies would be the inclusion of a measure of visual salience (for example <ref type="bibr" target="#b23">Itti et al., 1998;</ref><ref type="bibr" target="#b16">Garcia-Diaz et al., 2012)</ref> in order to control for possible effects of low-level features.</s><s xml:id="_QryBKjG">Since the exact salience definition to be used may depend on the research question, and the development in the field of salience models is still ongoing (see <ref type="bibr" target="#b8">Borji and Itti, 2013</ref> for a review), we refrained from picking one particular measure to be included with the database.</s><s xml:id="_vXbWRUA">Object eccentricity and object size are additional relevant measures to include <ref type="bibr" target="#b37">(Schomaker et al., 2017)</ref>.</s></p><p xml:id="_mYNus26"><s xml:id="_5gfC2U8">For the ratings of the entire scenes, we could not use the same set of scales as for the objects because interacting with an object (Interaction), owning an object (Desire to Own) and being familiar with an object (Recognizability) do not directly transfer to whole scenes.</s><s xml:id="_NmsZr2s">We therefore created two new scales: Interaction was intended to be replaced by Spending Time and Exploration.</s><s xml:id="_uVjyc32">The PCA results show that the motivational scales indeed loaded on the same factor.</s><s xml:id="_epZa7SM">Although the main aim of this database is to provide motivational ratings of everyday objects in the context of natural scenes, we include the scene ratings for completeness.</s></p><p xml:id="_eRwrjG7"><s xml:id="_uMJGnkb">One limitation of MONS is that according to ideas of subjective value, there are strong individual differences in preferences and thus valuation of objects/products <ref type="bibr" target="#b32">(Menger, 1950;</ref><ref type="bibr" target="#b40">Stigler, 1950;</ref><ref type="bibr" target="#b44">Von Mises and Greaves, 2007;</ref><ref type="bibr" target="#b18">Hare et al., 2009;</ref><ref type="bibr" target="#b2">Bartra et al., 2013)</ref>.</s><s xml:id="_nyceACU">Subjective values thus also depend on personal likes and dislikes.</s><s xml:id="_RKcnM87">Moreover, valuation and value-based decisions are state-dependent (e.g., depending on metabolic state: <ref type="bibr" target="#b42">Symmonds et al., 2010;</ref><ref type="bibr" target="#b28">Levy et al., 2013)</ref>.</s><s xml:id="_CgQkgaS">For example, the motivational value of a hotdog depends strongly on whether someone eats meat and what their calorie intake is for that day.</s><s xml:id="_ubTVp5b">Despite such individual preferences and state-dependent effects, we found that the scales were interpreted consistently and objects rated similarly by the raters.</s><s xml:id="_8Vd7ZcS">Another limitation of the database is that except for gender, age, and the level of education, the socioeconomic status and cultural characteristics of the participants are not known.</s><s xml:id="_vXWKY8T">Based on the methods of participant recruitment, most subjects can be expected to be from a European or general Western background <ref type="bibr" target="#b20">(Henrich et al., 2010)</ref>.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_9ntgPEj">CONCLUSION</head><p xml:id="_MMM9QsV"><s xml:id="_vCEf3hP">Motivational Objects in Natural Scenes provides a controlled set of common objects and scenes varying in motivational value that will be available for research on the effects of motivation on brain and behavior.</s><s xml:id="_Hpum5X2">In contrast to existing databases, the objects are available both in isolation and presented in a natural scene setting, while maintaining control of visual features such as lighting and visual angle and providing object location in the scene.</s><s xml:id="_TrKRA4c">All objects, scenes, and rating data can be downloaded free of charge at doi: 10.5281/zenodo.883110</s><s xml:id="_4gmCqZk">for use in noncommercial research projects.</s></p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>FIGURE 1 |</head><label>1</label><figDesc><div><p xml:id="_D2RKvdM"><s xml:id="_MPprkpd">FIGURE 1 | (A) Example of three versions of a realistic scene from which the objects were cut out.</s><s xml:id="_3wgAZna">In each version of the scene, one object was replaced that varied on the level of motivational value.</s><s xml:id="_3jm9kMg">On the top the appetitive version (a present), in the middle the neutral version (a shoe box), and on the bottom the aversive (an old carton) version.</s><s xml:id="_3MNwgru">All unique objects were cut out from the scene and rated separately.</s><s xml:id="_C62rpYC">(B) Example Motivational Objects in Natural Scenes objects on the motivation and valence dimensions for the objects in isolation ratings.</s><s xml:id="_CVFFFZc">Note, the object locations do not reflect exact values, but objects are spaced for demonstrational purposes.</s></p></div></figDesc><graphic coords="3,97.91,69.02,397.41,202.77" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc><div><p xml:id="_gnjUqxS"><s xml:id="_ZEXDkmv">scale for object ratings (Part I and Part II) and scene ratings (Part III) on 7-point Likert scales.</s><s xml:id="_VEGQ8xH">Does this scene make you calm or aroused?</s><s xml:id="_m6EjqT2">Calm-Neutral-Aroused Quality rating Quality Please rate the image quality Very poor-Fair-Excellent via mailing lists of several universities in Europe (including Germany, the Netherlands, and the United Kingdom), social media, and online message boards, creating a diverse group of respondents.</s><s xml:id="_U7F49pk">After completing the questionnaire participants could enter a draw to win one of forty 25 Euro (or equivalent) gift vouchers for an online store (Part I) or one of twenty 20 Euro (or equivalent) gift vouchers (Parts II and III).</s><s xml:id="_fmV2c3J">Data were collected through an internet-based survey system (Leiner, 2014).</s><s xml:id="_DCgpMng">Participants could pause the questionnaire to complete it a later convenient time.</s><s xml:id="_dudgGCQ">Completion of the questionnaire took around 35-45 min for objects in isolation (Part I), 25-30 min for objects in scenes (Part II), and 15-25 min for scenes (Part III).</s></p></div></figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>FIGURE 2 |</head><label>2</label><figDesc><div><p xml:id="_55VtQgt"><s xml:id="_mFFBdQ3">FIGURE 2 | Component loadings are shown for each scale.</s><s xml:id="_xJgFzgv">Part 1 (A): Ratings for objects in isolation for the motivational scales Approach/Avoid, Interaction, and Desire to Own all loaded highly on component 1 together with valence.</s><s xml:id="_x2UQDS8">Arousal loads highly on component 2, while Recognizability loads highly on component 3. Part II (B): Ratings for objects in scenes.</s><s xml:id="_a7TaPjS">The motivational scales (Approach/Avoid; Interaction; Desire to Own) all loaded highly on component 1 together with valence.</s><s xml:id="_XRnBwxd">Arousal loaded highly on component 2. Part III (C): Scene ratings for the Approach/Avoid, Spending Time, Exploration, Valence, and Arousal scales.</s><s xml:id="_AnMbA82">Approach/Avoid, Exploration, and Spending Time loaded highly on component 1, Valence and Approach/Avoid on component 2, and Arousal on component 3.</s></p></div></figDesc><graphic coords="7,103.65,69.02,385.92,129.78" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>FIGURE 3 |</head><label>3</label><figDesc><div><p xml:id="_hUrSWCJ"><s xml:id="_e5dWDjV">FIGURE 3 | Correlations between the objects-in-scenes ratings and the objects-in-isolation ratings for the different motivational scales (Top): Approach/Avoid, Desire to Own, and Interaction.</s><s xml:id="_dESEFgm">Note that scores on the non-motivational control scales Valence and Arousal (Bottom) show less variance, as intended.</s></p></div></figDesc><graphic coords="9,117.16,69.02,358.91,196.53" type="bitmap" /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>TABLE 1 |</head><label>1</label><figDesc><div><p xml:id="_3mRs7rE"><s xml:id="_Mm6pPh9">Rating questions per</s></p></div></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>TABLE 2 |</head><label>2</label><figDesc><div><p xml:id="_feaAGkX"><s xml:id="_K6uKY4F">Participant details per questionnaire type and version.</s></p></div></figDesc><table><row><cell>Questionnaire type and version</cell><cell>n</cell><cell>Female/male</cell><cell>Age range</cell><cell>Mean age in years</cell><cell>Education range</cell><cell>Mean Education</cell></row><row><cell>Objects in isolation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Version 1</cell><cell>38</cell><cell>24/14</cell><cell>18-44</cell><cell>25.4</cell><cell>2-6</cell><cell>3.6</cell></row><row><cell>Version 2</cell><cell>25</cell><cell>18/7</cell><cell>20-35</cell><cell>25.9</cell><cell>2-6</cell><cell>4.0</cell></row><row><cell>Version 3</cell><cell>38</cell><cell>16/22</cell><cell>18-37</cell><cell>25.5</cell><cell>2-6</cell><cell>3.5</cell></row><row><cell>Version 4</cell><cell>47</cell><cell>28/19</cell><cell>18-41</cell><cell>25.4</cell><cell>2-6</cell><cell>3.7</cell></row><row><cell>Version 5</cell><cell>43</cell><cell>22/21</cell><cell>19-45</cell><cell>26.7</cell><cell>2-6</cell><cell>4.2</cell></row><row><cell>Version 6</cell><cell>45</cell><cell>25/20</cell><cell>19-44</cell><cell>26.4</cell><cell>2-6</cell><cell>3.6</cell></row><row><cell>Version 7</cell><cell>40</cell><cell>29/11</cell><cell>19-35</cell><cell>25.8</cell><cell>2-6</cell><cell>4.1</cell></row><row><cell>Version 8</cell><cell>35</cell><cell>21/14</cell><cell>18-43</cell><cell>26.2</cell><cell>2-6</cell><cell>3.8</cell></row><row><cell>Version 9</cell><cell>32</cell><cell>21/11</cell><cell>18-39</cell><cell>25.6</cell><cell>2-6</cell><cell>3.6</cell></row><row><cell>Version 10</cell><cell>39</cell><cell>21/18</cell><cell>18-36</cell><cell>25.5</cell><cell>2-6</cell><cell>3.6</cell></row><row><cell>Version 11</cell><cell>26</cell><cell>11/15</cell><cell>18-36</cell><cell>26.0</cell><cell>2-6</cell><cell>3.7</cell></row><row><cell>Version 12</cell><cell>23</cell><cell>21/2</cell><cell>18-28</cell><cell>22.5</cell><cell>2-5</cell><cell>3.5</cell></row><row><cell>Subtotal</cell><cell>431</cell><cell>257/174</cell><cell>18-45</cell><cell>25.6</cell><cell>2-6</cell><cell>3.7</cell></row><row><cell>Objects in scenes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Version 1</cell><cell>29</cell><cell>19/10</cell><cell>18-40</cell><cell>25.3</cell><cell>2-6</cell><cell>3.6</cell></row><row><cell>Version 2</cell><cell>40</cell><cell>29/11</cell><cell>18-39</cell><cell>24.1</cell><cell>2-6</cell><cell>3.4</cell></row><row><cell>Version 3</cell><cell>26</cell><cell>20/6</cell><cell>19-34</cell><cell>23.9</cell><cell>2-6</cell><cell>3.5</cell></row><row><cell>Version 4</cell><cell>34</cell><cell>22/12</cell><cell>18-39</cell><cell>25.1</cell><cell>2-6</cell><cell>3.6</cell></row><row><cell>Version 5</cell><cell>31</cell><cell>25/6</cell><cell>18-45</cell><cell>24.0</cell><cell>1-6</cell><cell>3.3</cell></row><row><cell>Version 6</cell><cell>35</cell><cell>22/13</cell><cell>18-33</cell><cell>23.5</cell><cell>2-6</cell><cell>3.1</cell></row><row><cell>Subtotal</cell><cell>193</cell><cell>137/58</cell><cell>18-45</cell><cell>24.3</cell><cell>1-6</cell><cell>3.4</cell></row><row><cell>Scenes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Version 1</cell><cell>29</cell><cell>22/7</cell><cell>18-31</cell><cell>22.5</cell><cell>2-6</cell><cell>2.9</cell></row><row><cell>Version 2</cell><cell>24</cell><cell>19/5</cell><cell>19-45</cell><cell>25.7</cell><cell>2-6</cell><cell>3.3</cell></row><row><cell>Version 3</cell><cell>27</cell><cell>21/6</cell><cell>18-34</cell><cell>24.0</cell><cell>2-5</cell><cell>3.4</cell></row><row><cell>Version 4</cell><cell>30</cell><cell>21/9</cell><cell>18-43</cell><cell>24.1</cell><cell>2-6</cell><cell>3.4</cell></row><row><cell>Version 5</cell><cell>29</cell><cell>20/9</cell><cell>18-41</cell><cell>23.4</cell><cell>2-6</cell><cell>3.3</cell></row><row><cell>Version 6</cell><cell>24</cell><cell>18/6</cell><cell>19-35</cell><cell>23.9</cell><cell>2-6</cell><cell>3.4</cell></row><row><cell>Subtotal</cell><cell>163</cell><cell>121/42</cell><cell>18-45</cell><cell>23.9</cell><cell>2-6</cell><cell>3.4</cell></row><row><cell>Total</cell><cell>787</cell><cell>515/274</cell><cell>18-45</cell><cell>24.6</cell><cell>1-6</cell><cell>3.5</cell></row></table><note><p xml:id="_djbQxZP"><s xml:id="_EtmRQsX">Education: Level 1 = Primary/Elementary school; Level 2 = Secondary/High school; Level 3 = Some form of additional education (e.g., college or technical institute); Level 4 = Bachelor's degree; Level 5 = Master's degree; Level 6 = Doctorate/Professional degree.</s></p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>TABLE 3 |</head><label>3</label><figDesc><div><p xml:id="_fH8md9n"><s xml:id="_mEgwhKN">Motivational object category details for the ratings of objects in isolation (Part I).</s></p></div></figDesc><table><row><cell>Motivational object category</cell><cell>n</cell><cell>Range</cell><cell>Mean (SD)</cell></row><row><cell>Mean Motivation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aversive</cell><cell>136</cell><cell>1.30-3.49</cell><cell>2.97 (0.45)</cell></row><row><cell>Neutral</cell><cell>385</cell><cell>3.51-4.49</cell><cell>4.03 (0.27)</cell></row><row><cell>Appetitive</cell><cell>284</cell><cell>4.50-6.26</cell><cell>4.97 (0.38)</cell></row><row><cell>Motivation Total</cell><cell>805</cell><cell>1.30-6.26</cell><cell>4.18 (0.37)</cell></row><row><cell>Valence</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aversive</cell><cell>136</cell><cell>1.68-4.83</cell><cell>3.63 (0.49)</cell></row><row><cell>Neutral</cell><cell>385</cell><cell>3.25-5.40</cell><cell>4.06 (0.42)</cell></row><row><cell>Appetitive</cell><cell>284</cell><cell>3.37-6.02</cell><cell>4.64 (0.49)</cell></row><row><cell>Valence Total</cell><cell>805</cell><cell>1.68-6.02</cell><cell>4.19 (0.47)</cell></row><row><cell>Arousal</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aversive</cell><cell>136</cell><cell>2.61-5.50</cell><cell>3.74 (0.50)</cell></row><row><cell>Neutral</cell><cell>385</cell><cell>2.91-4.89</cell><cell>3.67 (0.39)</cell></row><row><cell>Appetitive</cell><cell>284</cell><cell>2.55-5.49</cell><cell>3.83 (0.50)</cell></row><row><cell>Arousal Total</cell><cell>805</cell><cell>2.55-5.50</cell><cell>3.74 (0.46)</cell></row><row><cell>Recognizability</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aversive</cell><cell>136</cell><cell>2.16-5.63</cell><cell>4.64 (0.70)</cell></row><row><cell>Neutral</cell><cell>385</cell><cell>2.17-6.24</cell><cell>4.88 (0.62)</cell></row><row><cell>Appetitive</cell><cell>284</cell><cell>4.19-6.03</cell><cell>5.21 (0.29)</cell></row><row><cell>Recognizability Total</cell><cell>805</cell><cell>2.16-6.24</cell><cell>4.96 (0.58)</cell></row></table><note><p xml:id="_2VVhYCZ"><s xml:id="_FtV8n9v">Objects were categorized post hoc on the basis of mean Motivation, collapsing over the Approach/Avoid, Desire to Own, and Interaction scales: Mean motivation ‚â§ 3.5: aversive; mean motivation 3.5-4.5:</s><s xml:id="_4VS4fZY">neutral; mean motivation ‚â• 4.5: appetitive.</s><s xml:id="_6KdG8U2">Ratings are reported for the aversive, neutral, and appetitive motivational post hoc categories.</s></p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>TABLE 4 |</head><label>4</label><figDesc><div><p xml:id="_5hH96UP"><s xml:id="_YG9w4Rz">Motivational object category details for the ratings of the objects in scenes (Part II).</s></p></div></figDesc><table><row><cell>Motivational object category</cell><cell>n</cell><cell>Range</cell><cell>Mean (SD)</cell></row><row><cell>Mean Motivation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aversive</cell><cell>104</cell><cell>1.16-3.49</cell><cell>2.67 (0.60)</cell></row><row><cell>Neutral</cell><cell>127</cell><cell>3.52-4.48</cell><cell>3.97 (0.26)</cell></row><row><cell>Appetitive</cell><cell>90</cell><cell>4.52-6.12</cell><cell>5.14 (0.40)</cell></row><row><cell>Motivation Total</cell><cell>321</cell><cell>1.16-6.12</cell><cell>3.88 (0.42)</cell></row><row><cell>Valence</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aversive</cell><cell>104</cell><cell>1.85-4.80</cell><cell>3.70 (0.55)</cell></row><row><cell>Neutral</cell><cell>127</cell><cell>3.19-4.88</cell><cell>3.96 (0.38)</cell></row><row><cell>Appetitive</cell><cell>90</cell><cell>3.58-5.63</cell><cell>4.65 (0.46)</cell></row><row><cell>Valence Total</cell><cell>321</cell><cell>1.85-5.63</cell><cell>4.08 (0.46)</cell></row><row><cell>Arousal</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aversive</cell><cell>104</cell><cell>2.95-5.32</cell><cell>3.83 (0.44)</cell></row><row><cell>Neutral</cell><cell>127</cell><cell>2.90-4.55</cell><cell>3.64 (0.34)</cell></row><row><cell>Appetitive</cell><cell>90</cell><cell>3.04-5.68</cell><cell>4.05 (0.46)</cell></row><row><cell>Arousal Total</cell><cell>321</cell><cell>2.90-5.68</cell><cell>3.82 (0.42)</cell></row></table><note><p xml:id="_9Zrd6f6"><s xml:id="_cRDDCm3">Objects were categorized post hoc on the basis of mean Motivation, collapsing over the Approach/Avoid, Desire to Own, and Interaction scales: Mean Motivation ‚â§ 3.5: aversive; mean Motivation 3.5-4.5:</s><s xml:id="_rSuv234">neutral; mean Motivation ‚â• 4.5: appetitive.</s><s xml:id="_RQEF4ve">Ratings are reported for the aversive, neutral, and appetitive motivational categories.</s></p></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>TABLE 5 |</head><label>5</label><figDesc><div><p xml:id="_8uaKswV"><s xml:id="_K8WEwTW">Motivational object category details for the ratings of the scenes (Part III).</s></p></div></figDesc><table><row><cell>Motivational object category</cell><cell>n</cell><cell>Range</cell><cell>Mean (SD)</cell></row><row><cell>Mean Motivation</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aversive</cell><cell>56</cell><cell>2.18-3.50</cell><cell>3.17 (0.32)</cell></row><row><cell>Neutral</cell><cell>214</cell><cell>3.52-4.49</cell><cell>3.98 (0.26)</cell></row><row><cell>Appetitive</cell><cell>51</cell><cell>4.53-5.58</cell><cell>4.77 (0.24)</cell></row><row><cell>Mean Motivation Total</cell><cell>321</cell><cell>2.18-5.58</cell><cell>3.96 (0.29)</cell></row><row><cell>Valence</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aversive</cell><cell>56</cell><cell>2.57-4.64</cell><cell>3.74 (0.39)</cell></row><row><cell>Neutral</cell><cell>214</cell><cell>2.93-5.00</cell><cell>3.86 (0.36)</cell></row><row><cell>Appetitive</cell><cell>51</cell><cell>3.65-5.76</cell><cell>4.53 (0.43)</cell></row><row><cell>Valence Total</cell><cell>321</cell><cell>2.57-5.76</cell><cell>3.96 (0.38)</cell></row><row><cell>Arousal</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aversive</cell><cell>56</cell><cell>2.91-4.52</cell><cell>3.70 (0.35)</cell></row><row><cell>Neutral</cell><cell>214</cell><cell>3.00-5.38</cell><cell>3.67 (0.33)</cell></row><row><cell>Appetitive</cell><cell>51</cell><cell>3.00-4.93</cell><cell>3.92 (0.42)</cell></row><row><cell>Arousal Total</cell><cell>321</cell><cell>2.91-5.38</cell><cell>3.72 (0.34)</cell></row><row><cell cols="4">Scenes were categorized post hoc on basis of the mean motivational ratings,</cell></row><row><cell cols="4">collapsing over the Approach/Avoid, Spending Time and Exploration scales.</cell></row><row><cell cols="4">Mean Motivation ‚â§ 3.5: aversive; mean Motivation 3.5-4.5: neutral; mean</cell></row><row><cell cols="4">Motivation ‚â• 4.5: appetitive. Ratings are reported for the aversive, neutral, and</cell></row><row><cell>appetitive motivational categories.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_0"><p xml:id="_SzkmfMm"><s xml:id="_qfC5pZW">Frontiers in Psychology | www.frontiersin.org</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" xml:id="foot_1"><p xml:id="_4NYZcqQ"><s xml:id="_7ZVKScH">September 2017 | Volume 8 | Article 1669</s></p></note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1" xml:id="foot_2"><p xml:id="_BAmzqjw"><s xml:id="_XFJxher">http://www.gimp.org</s><s xml:id="_ytWMSr8">Frontiers in Psychology | www.frontiersin.org</s></p></note>
		</body>
		<back>

			<div type="funding">
<div><head xml:id="_uT9aAdV">FUNDING</head><p xml:id="_EJf7hUW"><s xml:id="_s93AUyC">This research was supported by the <rs type="funder">German Research Foundation (DFG)</rs> grant <rs type="grantNumber">SFB/TRR 135</rs>, project <rs type="grantNumber">B01</rs>.</s></p></div>
			</div>
			<listOrg type="funding">
				<org type="funding" xml:id="_eMxDV2w">
					<idno type="grant-number">SFB/TRR 135</idno>
				</org>
				<org type="funding" xml:id="_jgFNbJR">
					<idno type="grant-number">B01</idno>
				</org>
			</listOrg>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_kpw9eJw">AUTHOR CONTRIBUTIONS</head><p xml:id="_xBPcds5"><s xml:id="_cRVmXBv">Study design: BW, JS, WE, and ER.</s><s xml:id="_puqrVXc">Stimulus creation and data acquisition: ER and JS.</s><s xml:id="_EJ57Qwb">Data analysis: JS and WE.</s><s xml:id="_AdjtbcZ">Writing: JS, BW, and WE.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_dCMVd9g">ACKNOWLEDGMENT</head><p xml:id="_jYFCTfu"><s xml:id="_9yeBYUR">We would like to thank Nora Reis for her help in photographing the scenes and Reinhard Bentrup for advice on data analysis.</s></p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head xml:id="_GAyA6er">Conflict of Interest Statement:</head><p xml:id="_eS2deH3"><s xml:id="_rCsA8Q3">The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</s></p><p xml:id="_Uu8HjNW"><s xml:id="_xaEXhY6">Copyright ¬© 2017 Schomaker, Rau, Einh√§user and Wittmann.</s><s xml:id="_zWztk5Q">This is an openaccess article distributed under the terms of the Creative Commons Attribution License (CC BY).</s><s xml:id="_snFAQZW">The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice.</s><s xml:id="_vjEWaAz">No use, distribution or reproduction is permitted which does not comply with these terms.</s></p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main" xml:id="_abDHaAf">Pleasure principles: A review of research on hedonic consumption</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">W</forename><surname>Alba</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Elanor</forename><forename type="middle">F</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jcps.2012.07.003</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_5ZAgMpM">Journal of Consumer Psychology</title>
		<title level="j" type="abbrev">J Consum Psychol</title>
		<idno type="ISSN">1057-7408</idno>
		<idno type="ISSNe">1532-7663</idno>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="18" />
			<date type="published" when="2013">2013</date>
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Alba, J. W., and Williams, E. F. (2013). Pleasure principles: a review of research on hedonic consumption. J. Consum. Psychol. 23, 2-18. doi: 10.1016/j.jcps.2012. 07.003</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main" xml:id="_DYBuWhF">Top-down versus bottom-up attentional control: a failed theoretical dichotomy</title>
		<author>
			<persName><forename type="first">Edward</forename><surname>Awh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Artem</forename><forename type="middle">V</forename><surname>Belopolsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jan</forename><surname>Theeuwes</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tics.2012.06.010</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_tTMXA6e">Trends in Cognitive Sciences</title>
		<title level="j" type="abbrev">Trends in Cognitive Sciences</title>
		<idno type="ISSN">1364-6613</idno>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="437" to="443" />
			<date type="published" when="2012-08">2012</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Awh, E., Belopolsky, A. V., and Theeuwes, J. (2012). Top-down versus bottom- up attentional control: a failed theoretical dichotomy. Trends Cogn. Sci. 16, 437-443. doi: 10.1016/j.tics.2012.06.010</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main" xml:id="_yy5Evj5">The valuation system: a coordinate-based meta-analysis of BOLD fMRI experiments examining neural correlates of subjective value</title>
		<author>
			<persName><forename type="first">O</forename><surname>Bartra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Mcguire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Kable</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2013.02.063</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_jNZRa67">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="412" to="427" />
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Bartra, O., McGuire, J. T., and Kable, J. W. (2013). The valuation system: a coordinate-based meta-analysis of BOLD fMRI experiments examining neural correlates of subjective value. Neuroimage 76, 412-427. doi: 10.1016/j. neuroimage.2013.02.063</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main" xml:id="_Wt6NSqp">Pleasure Systems in the Brain</title>
		<author>
			<persName><forename type="first">Kent</forename><forename type="middle">C</forename><surname>Berridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Morten</forename><forename type="middle">L</forename><surname>Kringelbach</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2015.02.018</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_jRVJKVp">Neuron</title>
		<title level="j" type="abbrev">Neuron</title>
		<idno type="ISSN">0896-6273</idno>
		<imprint>
			<biblScope unit="volume">86</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="646" to="664" />
			<date type="published" when="2015-05">2015</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Berridge, K. (2015). Pleasure systems in the brain. Neuron 86, 646-664. doi: 10.1016/j.neuron.2015.02.018</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main" xml:id="_Ht3v2Gt">‚ÄòLiking‚Äô and ‚Äòwanting‚Äô food rewards: Brain substrates and roles in eating disorders</title>
		<author>
			<persName><forename type="first">Kent</forename><forename type="middle">C</forename><surname>Berridge</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.physbeh.2009.02.044</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_MvateZm">Physiology &amp; Behavior</title>
		<title level="j" type="abbrev">Physiology &amp; Behavior</title>
		<idno type="ISSN">0031-9384</idno>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="537" to="550" />
			<date type="published" when="2009-07">2009</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Berridge, K. C. (2009). &apos;Liking&apos; and &apos;wanting&apos; food rewards: brain substrates and roles in eating disorders. Physiol. Behav. 97, 537-550. doi: 10.1016/j.physbeh. 2009.02.044</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main" xml:id="_jSKzjj8">What is the role of dopamine in reward: hedonic impact, reward learning, or incentive salience?</title>
		<author>
			<persName><forename type="first">Kent</forename><forename type="middle">C</forename><surname>Berridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><forename type="middle">E</forename><surname>Robinson</surname></persName>
		</author>
		<idno type="DOI">10.1016/s0165-0173(98)00019-8</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_UEVWP3K">Brain Research Reviews</title>
		<title level="j" type="abbrev">Brain Research Reviews</title>
		<idno type="ISSN">0165-0173</idno>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="309" to="369" />
			<date type="published" when="1998-12">1998</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Berridge, K. C., and Robinson, T. E. (1998). What is the role of dopamine in reward: hedonic impact, reward learning, or incentive salience? Brain Res. Rev. 28, 309-369. doi: 10.1016/S0165-0173(98)00019-8</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main" xml:id="_y3FfjWG">Dissecting components of reward: ‚Äòliking‚Äô, ‚Äòwanting‚Äô, and learning</title>
		<author>
			<persName><forename type="first">Kent</forename><forename type="middle">C</forename><surname>Berridge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Terry</forename><forename type="middle">E</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Wayne</forename><surname>Aldridge</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.coph.2008.12.014</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Sd5yD6W">Current Opinion in Pharmacology</title>
		<title level="j" type="abbrev">Current Opinion in Pharmacology</title>
		<idno type="ISSN">1471-4892</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="73" />
			<date type="published" when="2009-02">2009</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Berridge, K. C., Robinson, T. E., and Aldridge, J. W. (2009). Dissecting components of reward: &apos;liking&apos; , &apos;wanting&apos; , and learning. Curr. Opin. Pharmacol. 9, 65-73. doi: 10.1016/j.coph.2008.12.014</note>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main" xml:id="_W7ra9uC">Food-pics: an image database for experimental research on eating and appetite</title>
		<author>
			<persName><forename type="first">Jens</forename><surname>Blechert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Adrian</forename><surname>Meule</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Niko</forename><forename type="middle">A</forename><surname>Busch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kathrin</forename><surname>Ohla</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2014.00617</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_CJFYWMF">Frontiers in Psychology</title>
		<title level="j" type="abbrev">Front. Psychol.</title>
		<idno type="ISSNe">1664-1078</idno>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">617</biblScope>
			<date type="published" when="2014-06-24">2014</date>
			<publisher>Frontiers Media SA</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Blechert, J., Meule, A., Busch, N. A., and Ohla, K. (2014). Food-pics: an image database for experimental research on eating and appetite. Front. Psychol. 5:617. doi: 10.3389/fpsyg.2014.00617</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main" xml:id="_KvXJYQP">State-of-the-Art in Visual Attention Modeling</title>
		<author>
			<persName><forename type="first">Ali</forename><surname>Borji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Laurent</forename><surname>Itti</surname></persName>
		</author>
		<idno type="DOI">10.1109/tpami.2012.89</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_WyuXmGb">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<title level="j" type="abbrev">IEEE Trans. Pattern Anal. Mach. Intell.</title>
		<idno type="ISSN">0162-8828</idno>
		<idno type="ISSNe">2160-9292</idno>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="185" to="207" />
			<date type="published" when="2013-01">2013</date>
			<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Borji, A., and Itti, L. (2013). State-of-the-art in visual attention modeling. IEEE Trans. Pattern Anal. Mach. Intell. 35, 185-207. doi: 10.1109/TPAMI.2012.</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main" xml:id="_JgYGDma">Mechanisms of motivation‚Äìcognition interaction: challenges and opportunities</title>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">S</forename><surname>Braver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marie</forename><forename type="middle">K</forename><surname>Krug</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kimberly</forename><forename type="middle">S</forename><surname>Chiew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wouter</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Andrew</forename><surname>Westbrook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Nathan</forename><forename type="middle">J</forename><surname>Clement</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">Alison</forename><surname>Adcock</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Deanna</forename><forename type="middle">M</forename><surname>Barch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Matthew</forename><forename type="middle">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Charles</forename><forename type="middle">S</forename><surname>Carver</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Roshan</forename><surname>Cools</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ruud</forename><surname>Custers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Anthony</forename><surname>Dickinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Carol</forename><forename type="middle">S</forename><surname>Dweck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ayelet</forename><surname>Fishbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">M</forename><surname>Gollwitzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Thomas</forename><forename type="middle">M</forename><surname>Hess</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Derek</forename><forename type="middle">M</forename><surname>Isaacowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mara</forename><surname>Mather</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kou</forename><surname>Murayama</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Luiz</forename><surname>Pessoa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">R</forename><surname>Samanez-Larkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Leah</forename><forename type="middle">H</forename><surname>Somerville</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13415-014-0300-0</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_b3PWKjj">Cognitive, Affective, &amp; Behavioral Neuroscience</title>
		<title level="j" type="abbrev">Cogn Affect Behav Neurosci</title>
		<idno type="ISSN">1530-7026</idno>
		<idno type="ISSNe">1531-135X</idno>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="443" to="472" />
			<date type="published" when="2014-06">2014</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Braver, T. S., Krug, M. K., Chiew, K. S., Kool, W., Westbrook, J. A., Clement, N. J., et al. (2014). Mechanisms of motivation-cognition interaction: challenges and opportunities. Cogn. Affect. Behav. Neurosci. 14, 443-472. doi: 10.3758/s13415- 014-0300-0</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main" xml:id="_ZrR4eA3">Faces and text attract gaze independent of the task: Experimental data and computer model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cerf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Frady</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<idno type="DOI">10.1167/9.12.10</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_HyZVxHb">Journal of Vision</title>
		<title level="j" type="abbrev">Journal of Vision</title>
		<idno type="ISSNe">1534-7362</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="10" to="10" />
			<date type="published" when="2009-11-01">2009</date>
			<publisher>Association for Research in Vision and Ophthalmology (ARVO)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Cerf, M., Frady, E. P., and Koch, C. (2009). Faces and text attract gaze independent of the task: experimental data and computer model. J. Vis. 9, 1-15. doi: 10.1167/ 9.12.10</note>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main" xml:id="_kY7V2Q4">Predicting human gaze using low-level saliency combined with face detection</title>
		<author>
			<persName><forename type="first">M</forename><surname>Cerf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Harel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Einh√§user</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m" xml:id="_H8W6EQE">Proceedings of the 20th International Conference on Neural Information Processing Systems (NIPS&apos;07)</title>
		<meeting>the 20th International Conference on Neural Information Processing Systems (NIPS&apos;07)<address><addrLine>Vancouver, BC</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008">2008</date>
			<biblScope unit="page" from="241" to="248" />
		</imprint>
	</monogr>
	<note type="raw_reference">Cerf, M., Harel, J., Einh√§user, W., and Koch, C. (2008). &quot;Predicting human gaze using low-level saliency combined with face detection, &quot; in Proceedings of the 20th International Conference on Neural Information Processing Systems (NIPS&apos;07), Vancouver, BC, 241-248.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main" xml:id="_xnrZ27k">Evidence for a Common Representation of Decision Values for Dissimilar Goods in Human Ventromedial Prefrontal Cortex</title>
		<author>
			<persName><forename type="first">Vikram</forename><forename type="middle">S</forename><surname>Chib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shinsuke</forename><surname>Shimojo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">P</forename><surname>O'doherty</surname></persName>
		</author>
		<idno type="DOI">10.1523/jneurosci.2575-09.2009</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_SyFkeeu">The Journal of Neuroscience</title>
		<title level="j" type="abbrev">J. Neurosci.</title>
		<idno type="ISSN">0270-6474</idno>
		<idno type="ISSNe">1529-2401</idno>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">39</biblScope>
			<biblScope unit="page" from="12315" to="12320" />
			<date type="published" when="2009-09-30">2009</date>
			<publisher>Society for Neuroscience</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Chib, V. S., Rangel, A., Shimojo, S., and O&apos;Doherty, J. P. (2009). Evidence for a common representation of decision values for dissimilar goods in human ventromedial prefrontal cortex. J. Neurosci. 29, 12315-12320. doi: 10.1523/ JNEUROSCI.2575-09.2009</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main" xml:id="_utF7j9R">Handbook of Consumer Psychology</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">B</forename><surname>Andrade</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780203809570</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_XTRkmsD">Handbook of Consumer Psychology</title>
		<editor>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Haugtvedt</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">P</forename><surname>Herr</surname></persName>
		</editor>
		<editor>
			<persName><forename type="first">F</forename><surname>Kardes</surname></persName>
		</editor>
		<meeting><address><addrLine>Mahwah, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge</publisher>
			<date type="published" when="2008">2008</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Cohen, J. B., Pham, M. T., and Andrade, E. B. (2008). &quot;The nature and role of affect in consumer behavior, &quot; in Handbook of Consumer Psychology, eds C. P. Haugtvedt, P. Herr, and F. Kardes (Mahwah, NJ: Lawrence Erlbaum).</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main" xml:id="_j6vPh5D">The Hierarchical Model of Approach-Avoidance Motivation</title>
		<author>
			<persName><forename type="first">Andrew</forename><forename type="middle">J</forename><surname>Elliot</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11031-006-9028-7</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_7Yv6VEa">Motivation and Emotion</title>
		<title level="j" type="abbrev">Motiv Emot</title>
		<idno type="ISSN">0146-7239</idno>
		<idno type="ISSNe">1573-6644</idno>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="111" to="116" />
			<date type="published" when="2006-07-25">2006</date>
			<publisher>Springer Science and Business Media LLC</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Elliot, A. J. (2006). The hierarchical model of approach-avoidance motivation. Motiv. Emot. 30, 111-116. doi: 10.1007/s11031-006-9028-7</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main" xml:id="_3bdG8cd">A Model Of Emotion-Driven Choice</title>
		<author>
			<persName><forename type="first">Richard</forename><surname>Elliott</surname></persName>
		</author>
		<idno type="DOI">10.1362/026725798784959408</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_UM77Dvv">Journal of Marketing Management</title>
		<title level="j" type="abbrev">Journal of Marketing Management</title>
		<idno type="ISSN">0267-257X</idno>
		<idno type="ISSNe">1472-1376</idno>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1-3</biblScope>
			<biblScope unit="page" from="95" to="108" />
			<date type="published" when="1998-04">1998</date>
			<publisher>Informa UK Limited</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Elliott, R. (1998). A model of emotion-driven choice. J. Mark. Manage. 14, 95-108. doi: 10.1362/026725798784959408</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main" xml:id="_f8XT6tf">Saliency from hierarchical adaptation through decorrelation and variance normalization</title>
		<author>
			<persName><forename type="first">Ant√≥n</forename><surname>Garcia-Diaz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xos√©</forename><forename type="middle">R</forename><surname>Fdez-Vidal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xos√©</forename><forename type="middle">M</forename><surname>Pardo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Raquel</forename><surname>Dosil</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.imavis.2011.11.007</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_DzYxhFe">Image and Vision Computing</title>
		<title level="j" type="abbrev">Image and Vision Computing</title>
		<idno type="ISSN">0262-8856</idno>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="64" />
			<date type="published" when="2012-01">2012</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Garcia-Diaz, A., Fdez-Vidal, X. R., Pardo, X. M., and Dosil, R. (2012). Saliency from hierarchical adaptation through decorrelation and variance normalization. Image Vision Comput. 30, 51-64. doi: 10.1016/j.imavis.2011.11.007</note>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main" xml:id="_F6HJk24">The Ecological Approach to Visual Perception</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Gibson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979">1979</date>
			<publisher>Houghton Mifflin</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Gibson, J. J. (1979). The Ecological Approach to Visual Perception. London: Houghton Mifflin.</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main" xml:id="_7ZUK5Nd">Self-Control in Decision-Making Involves Modulation of the vmPFC Valuation System</title>
		<author>
			<persName><forename type="first">Todd</forename><forename type="middle">A</forename><surname>Hare</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Colin</forename><forename type="middle">F</forename><surname>Camerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antonio</forename><surname>Rangel</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1168450</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XfCnRyX">Science</title>
		<title level="j" type="abbrev">Science</title>
		<idno type="ISSN">0036-8075</idno>
		<idno type="ISSNe">1095-9203</idno>
		<imprint>
			<biblScope unit="volume">324</biblScope>
			<biblScope unit="issue">5927</biblScope>
			<biblScope unit="page" from="646" to="648" />
			<date type="published" when="2009-05">2009</date>
			<publisher>American Association for the Advancement of Science (AAAS)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Hare, T. A., Camerer, C. F., and Rangel, A. (2009). Self-control in decision-making involves modulation of the vmPFC valuation system. Science 324, 646-648. doi: 10.1126/science.1168450</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main" xml:id="_WCspdvm">Attention in natural scenes: contrast affects rapid visual processing and fixations alike</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Hart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">C</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Klein-Harmeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Einhauser</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.2013.0067</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_GMExAr9">Philos. Trans. R. Soc. Lond. B Biol. Sci</title>
		<imprint>
			<biblScope unit="volume">368</biblScope>
			<biblScope unit="page">20130067</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Hart, B. M., Schmidt, H. C., Klein-Harmeyer, I., and Einhauser, W. (2013). Attention in natural scenes: contrast affects rapid visual processing and fixations alike. Philos. Trans. R. Soc. Lond. B Biol. Sci. 368:20130067. doi: 10.1098/rstb. 2013.0067</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main" xml:id="_z5zSAFY">The weirdest people in the world?</title>
		<author>
			<persName><forename type="first">Joseph</forename><surname>Henrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Steven</forename><forename type="middle">J</forename><surname>Heine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ara</forename><surname>Norenzayan</surname></persName>
		</author>
		<idno type="DOI">10.1017/s0140525x0999152x</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_NsmsJWs">Behavioral and Brain Sciences</title>
		<title level="j" type="abbrev">Behav Brain Sci</title>
		<idno type="ISSN">0140-525X</idno>
		<idno type="ISSNe">1469-1825</idno>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="61" to="83" />
			<date type="published" when="2010-06">2010</date>
			<publisher>Cambridge University Press (CUP)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Henrich, J., Heine, S. J., and Norenzayan, A. (2010). The weirdest people in the world? Behav. Brain Sci. 33, 61-83; discussion 83-135. doi: 10.1017/ S0140525X0999152X</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main" xml:id="_ye7S4Cg">Reward guides attention to object categories in real-world scenes.</title>
		<author>
			<persName><forename type="first">Clayton</forename><surname>Hickey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Kaiser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marius</forename><forename type="middle">V</forename><surname>Peelen</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0038627</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_eB9y9Vy">Journal of Experimental Psychology: General</title>
		<title level="j" type="abbrev">Journal of Experimental Psychology: General</title>
		<idno type="ISSN">0096-3445</idno>
		<idno type="ISSNe">1939-2222</idno>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="264" to="273" />
			<date type="published" when="2015">2015</date>
			<publisher>American Psychological Association (APA)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Hickey, C., Kaiser, D., and Peelen, M. V. (2015). Reward guides attention to object categories in real-world scenes. J. Exp. Psychol. Gen. 144, 264-273. doi: 10.1037/ a0038627</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main" xml:id="_kuDuyeN">Beyond pleasure and pain.</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Higgins</surname></persName>
		</author>
		<idno type="DOI">10.1037/0003-066x.52.12.1280</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_PDMehB4">American Psychologist</title>
		<title level="j" type="abbrev">American Psychologist</title>
		<idno type="ISSN">0003-066X</idno>
		<idno type="ISSNe">1935-990X</idno>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1280" to="1300" />
			<date type="published" when="1997-12">1997</date>
			<publisher>American Psychological Association (APA)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Higgins, E. T. (1997). Beyond pleasure and pain. Am. Psychol. 52, 1280-1300. doi: 10.1037/0003-066X.52.12.1280</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main" xml:id="_xsgwx3G">A model of saliency-based visual attention for rapid scene analysis</title>
		<author>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Niebur</surname></persName>
		</author>
		<idno type="DOI">10.1109/34.730558</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_pqRmkfF">IEEE Transactions on Pattern Analysis and Machine Intelligence</title>
		<title level="j" type="abbrev">IEEE Trans. Pattern Anal. Machine Intell.</title>
		<idno type="ISSN">0162-8828</idno>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1254" to="1259" />
			<date type="published" when="1998">1998</date>
			<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Itti, L., Koch, C., and Niebur, E. (1998). A model of saliency-based visual attention for rapid scene analysis. IEEE Trans. Pattern Anal. Mach. Intell. 20, 1254-1259. doi: 10.1109/34.730558</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main" xml:id="_gfrasNY">The Varimax Criterion for Analytic Rotation in Factor Analysis</title>
		<author>
			<persName><forename type="first">Henry</forename><forename type="middle">F</forename><surname>Kaiser</surname></persName>
		</author>
		<idno type="DOI">10.1007/bf02289233</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_kP6xZ2h">Psychometrika</title>
		<title level="j" type="abbrev">Psychometrika</title>
		<idno type="ISSN">0033-3123</idno>
		<idno type="ISSNe">1860-0980</idno>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="187" to="200" />
			<date type="published" when="1958-09">1958</date>
			<publisher>Cambridge University Press (CUP)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Kaiser, H. F. (1958). The varimax criterion for analytic rotation in factor analysis. Psychometrika 23, 187-200. doi: 10.1007/Bf02289233</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main" xml:id="_GZUZ53t">Neural Predictors of Purchases</title>
		<author>
			<persName><forename type="first">Brian</forename><surname>Knutson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><surname>Rick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">Elliott</forename><surname>Wimmer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Drazen</forename><surname>Prelec</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><surname>Loewenstein</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2006.11.010</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Bf6AU64">Neuron</title>
		<title level="j" type="abbrev">Neuron</title>
		<idno type="ISSN">0896-6273</idno>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="147" to="156" />
			<date type="published" when="2007-01">2007</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Knutson, B., Rick, S., Wimmer, G. E., Prelec, D., and Loewenstein, G. (2007). Neural predictors of purchases. Neuron 53, 147-156. doi: 10.1016/j.neuron. 2006.11.010</note>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main" xml:id="_c7mjZSw">International Affective Picture System (IAPS): Affective Ratings of Pictures and Instruction Manual</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename><surname>Cuthbert</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008">2008</date>
			<pubPlace>Gainesville, FL</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Florida</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Technical report A-8</note>
	<note type="raw_reference">Lang, P. J., Bradley, M. M., and Cuthbert, B. N. (2008). International Affective Picture System (IAPS): Affective Ratings of Pictures and Instruction Manual. Technical report A-8. Gainesville, FL: University of Florida.</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main" xml:id="_z6cfwwh">Statistical Software Survey</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Leiner</surname></persName>
		</author>
		<idno type="DOI">10.1287/orms.2015.01.11</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_a83rW2d">Computer Software</title>
		<imprint>
			<date type="published" when="2014-02-20">2014. February 20, 2015</date>
			<publisher>Institute for Operations Research and the Management Sciences (INFORMS)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Leiner, D. J. (2014). SoSci Survey (Version 2.4. 00-i) [Computer Software]. [Accessed February 20, 2015].</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main" xml:id="_G4UZp44">State dependent valuation: the effect of deprivation on risk preferences</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Thavikulwat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Glimcher</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0053978</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_BZ5CUmA">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">53978</biblScope>
			<date type="published" when="2013">2013</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Levy, D. J., Thavikulwat, A. C., and Glimcher, P. W. (2013). State dependent valuation: the effect of deprivation on risk preferences. PLOS ONE 8:e53978. doi: 10.1371/journal.pone.0053978</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main" xml:id="_sYPPqnn">Choice from Non-Choice: Predicting Consumer Preferences from Blood Oxygenation Level-Dependent Signals Obtained during Passive Viewing</title>
		<author>
			<persName><forename type="first">Ifat</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Stephanie</forename><forename type="middle">C</forename><surname>Lazzaro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Robb</forename><forename type="middle">B</forename><surname>Rutledge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Paul</forename><forename type="middle">W</forename><surname>Glimcher</surname></persName>
		</author>
		<idno type="DOI">10.1523/jneurosci.3214-10.2011</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_XJ9R3yd">The Journal of Neuroscience</title>
		<title level="j" type="abbrev">J. Neurosci.</title>
		<idno type="ISSN">0270-6474</idno>
		<idno type="ISSNe">1529-2401</idno>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="118" to="125" />
			<date type="published" when="2011-01-05">2011</date>
			<publisher>Society for Neuroscience</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Levy, I., Lazzaro, S. C., Rutledge, R. B., and Glimcher, P. W. (2011). Choice from non-choice: predicting consumer preferences from blood oxygenation level- dependent signals obtained during passive viewing. J. Neurosci. 31, 118-125. doi: 10.1523/JNEUROSCI.3214-10.2011</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main" xml:id="_bBqRXXZ">A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Martin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fowlkes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Tal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Malik</surname></persName>
		</author>
		<idno type="DOI">10.1109/iccv.2001.937655</idno>
	</analytic>
	<monogr>
		<title level="m" xml:id="_UGRqAwg">Proceedings Eighth IEEE International Conference on Computer Vision. ICCV 2001</title>
		<meeting>Eighth IEEE International Conference on Computer Vision. ICCV 2001<address><addrLine>Vancouver, BC</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Comput. Soc</publisher>
			<date type="published" when="2001">2001. 2001</date>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
	<note>ICCV 2001</note>
	<note type="raw_reference">Martin, D., Fowlkes, C., Tal, D., and Malik, J. (2001). &quot;A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics, &quot; in Proceedings of the Eighth IEEE International Conference on Computer Vision, 2001. ICCV 2001, Vol. 2, (Vancouver, BC: IEEE), 416-423. doi: 10.1109/ICCV.2001.93 7655</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main" xml:id="_e6AWqJz">Rapid serial processing of natural scenes: Color modulates detection but neither recognition nor the attentional blink</title>
		<author>
			<persName><forename type="first">S</forename><surname>Marx</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Hansen-Goos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Einhauser</surname></persName>
		</author>
		<idno type="DOI">10.1167/14.14.4</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_cx7Cmy4">Journal of Vision</title>
		<title level="j" type="abbrev">Journal of Vision</title>
		<idno type="ISSNe">1534-7362</idno>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="4" to="4" />
			<date type="published" when="2014-12-16">2014</date>
			<publisher>Association for Research in Vision and Ophthalmology (ARVO)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Marx, S., Hansen-Goos, O., Thrun, M., and Einhauser, W. (2014). Rapid serial processing of natural scenes: color modulates detection but neither recognition nor the attentional blink. J. Vis. 14, 4. doi: 10.1167/14.14.4</note>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Menger</surname></persName>
		</author>
		<title level="m" xml:id="_ajBdk57">Principles of Economics. First, General Part</title>
		<meeting><address><addrLine>Glencoe, IL</addrLine></address></meeting>
		<imprint>
			<publisher>Free Press</publisher>
			<date type="published" when="1950">1950</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Menger, C. (1950). Principles of Economics. First, General Part. Glencoe, IL: Free Press.</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main" xml:id="_MvzG64g">Meet OLAF, a Good Friend of the IAPS! The Open Library of Affective Foods: A Tool to Investigate the Emotional Impact of Food in Adolescents</title>
		<author>
			<persName><forename type="first">Laura</forename><surname>Miccoli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Rafael</forename><surname>Delgado</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sonia</forename><surname>Rodr√≠guez-Ruiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pedro</forename><surname>Guerra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Eduardo</forename><surname>Garc√≠a-M√°rmol</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Carmen</forename><surname>Fern√°ndez-Santaella</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0114515</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_wepFxyz">PLoS ONE</title>
		<title level="j" type="abbrev">PLoS ONE</title>
		<idno type="ISSNe">1932-6203</idno>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page">e114515</biblScope>
			<date type="published" when="2014-12-09">2014</date>
			<publisher>Public Library of Science (PLoS)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Miccoli, L., Delgado, R., Rodriguez-Ruiz, S., Guerra, P., Garcia-Marmol, E., and Fernandez-Santaella, M. C. (2014). Meet OLAF, a good friend of the IAPS! The Open Library of Affective Foods: a tool to investigate the emotional impact of food in adolescents. PLOS ONE 9:e114515. doi: 10.1371/journal.pone.011</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main" xml:id="_MfrU2C5">Making a ‚ÄúCompletely Blind‚Äù Image Quality Analyzer</title>
		<author>
			<persName><forename type="first">A</forename><surname>Mittal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Soundararajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bovik</surname></persName>
		</author>
		<idno type="DOI">10.1109/lsp.2012.2227726</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_Djuzyb7">IEEE Signal Processing Letters</title>
		<title level="j" type="abbrev">IEEE Signal Process. Lett.</title>
		<idno type="ISSN">1070-9908</idno>
		<idno type="ISSNe">1558-2361</idno>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="212" />
			<date type="published" when="2013-03">2013</date>
			<publisher>Institute of Electrical and Electronics Engineers (IEEE)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Mittal, A., Soundararajan, R., and Bovik, A. C. (2013). Making a &quot;completely blind&quot; image quality analyzer. Signal Process. Lett. 20, 209-212. doi: 10.1109/LSP.2012. 2227726</note>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main" xml:id="_ABm94vn">R: A Language and Environment for Statistical Computing</title>
		<author>
			<persName><forename type="first">Team</forename><surname>Core</surname></persName>
		</author>
		<idno type="DOI">10.32614/r.manuals</idno>
		<imprint>
			<date type="published" when="2014">2014</date>
			<publisher>R Foundation for Statistical Computing</publisher>
			<pubPlace>Vienna</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">R Core Team (2014). R: A Language and Environment for Statistical Computing. Vienna: R Foundation for Statistical Computing.</note>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main" xml:id="_7Nfe3dv">A circumplex model of affect.</title>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">A</forename><surname>Russell</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0077714</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_zkPag68">Journal of Personality and Social Psychology</title>
		<title level="j" type="abbrev">Journal of Personality and Social Psychology</title>
		<idno type="ISSN">0022-3514</idno>
		<idno type="ISSNe">1939-1315</idno>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1161" to="1178" />
			<date type="published" when="1980-12">1980</date>
			<publisher>American Psychological Association (APA)</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Russell, J. A. (1980). A circumplex model of affect. J. Pers. Soc. Psychol. 39, 1161-1178. doi: 10.1037/h0077714</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main" xml:id="_nXWEc5C">Attention in natural scenes: Affective-motivational factors guide gaze independently of visual salience</title>
		<author>
			<persName><forename type="first">Judith</forename><surname>Schomaker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Daniel</forename><surname>Walper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bianca</forename><forename type="middle">C</forename><surname>Wittmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Einh√§user</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2017.02.003</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_2R96W7X">Vision Research</title>
		<title level="j" type="abbrev">Vision Research</title>
		<idno type="ISSN">0042-6989</idno>
		<imprint>
			<biblScope unit="volume">133</biblScope>
			<biblScope unit="page" from="161" to="175" />
			<date type="published" when="2017-04">2017</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Schomaker, J., Walper, D., Wittmann, B. C., and Einhauser, W. (2017). Attention in natural scenes: affective-motivational factors guide gaze independently of visual salience. Vision Res. 133, 161-175. doi: 10.1016/j.visres.2017. 02.003</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main" xml:id="_GAQSqHq">The marketing implications of affective product design</title>
		<author>
			<persName><forename type="first">Rosemary</forename><forename type="middle">R</forename><surname>Seva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Henry Been-Lirn</forename><surname>Duh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Martin</forename><forename type="middle">G</forename><surname>Helander</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.apergo.2006.12.001</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_9qtqZSj">Applied Ergonomics</title>
		<title level="j" type="abbrev">Applied Ergonomics</title>
		<idno type="ISSN">0003-6870</idno>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="723" to="731" />
			<date type="published" when="2007-11">2007</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Seva, R. R., Duh, H. B.-L., and Helander, M. G. (2007). The marketing implications of affective product design. Appl. Ergon. 38, 723-731. doi: 10.1016/j.apergo. 2006.12.001</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main" xml:id="_hjzuEVh">The Behavior of Organisms: An Experimental Analysis</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">F</forename><surname>Skinner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1938">1938</date>
			<publisher>Appleton-Century-Crofts</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Skinner, B. F. (1938). The Behavior of Organisms: An Experimental Analysis. New York, NY: Appleton-Century-Crofts.</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main" xml:id="_7Wj66WE">The Development of Utility Theory. I</title>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">J</forename><surname>Stigler</surname></persName>
		</author>
		<idno type="DOI">10.1086/256962</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_EYvxe7Q">Journal of Political Economy</title>
		<title level="j" type="abbrev">Journal of Political Economy</title>
		<idno type="ISSN">0022-3808</idno>
		<idno type="ISSNe">1537-534X</idno>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="307" to="327" />
			<date type="published" when="1950-08">1950</date>
			<publisher>University of Chicago Press</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Stigler, G. J. (1950). The development of utility theory. I. J. Polit. Econ. 58, 307-327. doi: 10.1086/256962</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main" xml:id="_h8gKBSq">Overt attention in natural scenes: Objects dominate features</title>
		<author>
			<persName><forename type="first">Josef</forename><surname>Stoll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Michael</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Antje</forename><surname>Nuthmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wolfgang</forename><surname>Einh√§user</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.visres.2014.11.006</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_p7GnWDq">Vision Research</title>
		<title level="j" type="abbrev">Vision Research</title>
		<idno type="ISSN">0042-6989</idno>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="36" to="48" />
			<date type="published" when="2015-02">2015</date>
			<publisher>Elsevier BV</publisher>
		</imprint>
	</monogr>
	<note type="raw_reference">Stoll, J., Thrun, M., Nuthmann, A., and Einhauser, W. (2015). Overt attention in natural scenes: objects dominate features. Vision Res. 107, 36-48. doi: 10.1016/ j.visres.2014.11.006</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main" xml:id="_fvJUyyG">Metabolic state alters economic decision making under risk in humans</title>
		<author>
			<persName><forename type="first">M</forename><surname>Symmonds</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Emmanuel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Drew</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Batterham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0011090</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_VHBEmGt">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">11090</biblScope>
			<date type="published" when="2010">2010</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Symmonds, M., Emmanuel, J. J., Drew, M. E., Batterham, R. L., and Dolan, R. J. (2010). Metabolic state alters economic decision making under risk in humans. PLOS ONE 5:e11090. doi: 10.1371/journal.pone.0011090</note>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main" xml:id="_cFrkWtf">Animal intelligence; experimental studies</title>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">L</forename><surname>Thorndike</surname></persName>
		</author>
		<idno type="DOI">10.5962/bhl.title.55072</idno>
		<imprint>
			<date type="published" when="1911">1911</date>
			<publisher>The Macmillan Company</publisher>
			<pubPlace>New York, NY</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Thorndike, E. L. (1911). Animal Intelligence: Experimental Studies. New York, NY: Macmillan. doi: 10.5962/bhl.title.55072</note>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main" xml:id="_bNgSwWc">Human Action: A Treatise on Economics</title>
		<author>
			<persName><forename type="first">Von</forename><surname>Mises</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Greaves</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">B</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2007">2007</date>
			<publisher>Liberty Fund</publisher>
			<pubPlace>Indianapolis, IN</pubPlace>
		</imprint>
	</monogr>
	<note type="raw_reference">Von Mises, L., and Greaves, B. B. (2007). Human Action: A Treatise on Economics. Indianapolis, IN: Liberty Fund.</note>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main" xml:id="_EDr5ghS">Psychology as the behaviorist views it</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Watson</surname></persName>
		</author>
		<idno type="DOI">10.1037/h0074428</idno>
	</analytic>
	<monogr>
		<title level="j" xml:id="_6gtEJBF">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="158" to="177" />
			<date type="published" when="1913">1913</date>
		</imprint>
	</monogr>
	<note type="raw_reference">Watson, J. B. (1913). Psychology as the behaviorist views it. Psychol. Rev. 20, 158-177. doi: 10.1037/h0074428</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
